{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import typing\nimport pandas as pd\nimport re\nimport functools\nimport numpy as np\nimport math\n","metadata":{"_uuid":"b856d7ba-2c34-4ad8-b382-9420bb9367f4","_cell_guid":"385e0461-440c-4f20-8070-11a2863e0c97","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-12T19:38:30.877487Z","iopub.execute_input":"2025-03-12T19:38:30.877741Z","iopub.status.idle":"2025-03-12T19:38:32.101193Z","shell.execute_reply.started":"2025-03-12T19:38:30.877717Z","shell.execute_reply":"2025-03-12T19:38:32.100051Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"class Token:\n    def __init__(self, type: str, value: str):\n        self.type = type\n        self.value = value\n\n    def __repr__(self):\n        return f\"Token({self.type}, '{self.value}')\"","metadata":{"_uuid":"8ff011af-2378-4d79-ae95-db73713569bd","_cell_guid":"952122dc-d297-4cb6-9c3d-ac0917db75ec","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-12T19:38:32.102327Z","iopub.execute_input":"2025-03-12T19:38:32.102946Z","iopub.status.idle":"2025-03-12T19:38:32.108551Z","shell.execute_reply.started":"2025-03-12T19:38:32.102902Z","shell.execute_reply":"2025-03-12T19:38:32.107270Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class ParseTreeNode:\n    def __init__(self, type: str, value: typing.Optional[str] = None, children: typing.Optional[typing.List[\"ParseTreeNode\"]] = None):\n        self.type = type\n        self.value = value\n        self.children = children or []\n        self.start_index = None\n        self.end_index = None\n\n    def __repr__(self):\n        return f\"ParseTreeNode({self.type}, value={self.value}, children={self.children}, start_index={self.start_index}, end_index={self.end_index})\"\n    \n    def reify(self, function_factory):\n        if (self.type == \"expression\") and len(self.children) == 3 and self.children[0].type == \"term\" and self.children[1].value == \"+\" and self.children[2].type == \"term\":\n            arg0 = self.children[0].reify(function_factory)\n            arg1 = self.children[2].reify(function_factory)\n            if(isinstance(arg0, int) or isinstance(arg0, float)) and (isinstance(arg1, int) or isinstance(arg1, float)):\n                return arg0 + arg1\n            else:\n                # we need to use late binding\n                f = function_factory.get(\"Add\")\n                params = {}\n                pkeys = [a for a in f.parameters.keys()]\n                params[pkeys[0]] = arg0\n                params[pkeys[1]] = arg1\n                return f.create_function(**params)\n        # TODO: this doesn't have the associative property, so it's necessary to flatten the tree if we want to do away with the requirement for parentheses\n        if (self.type == \"expression\") and len(self.children) == 3 and self.children[0].type == \"term\" and self.children[1].value == \"-\" and self.children[2].type == \"term\":\n            arg0 = self.children[0].reify(function_factory)\n            arg1 = self.children[2].reify(function_factory)\n            if(isinstance(arg0, int) or isinstance(arg0, float)) and (isinstance(arg1, int) or isinstance(arg1, float)):\n                return arg0 - arg1\n            else:\n                # we need to use late binding\n                f = function_factory.get(\"Sub\")\n                params = {}\n                pkeys = [a for a in f.parameters.keys()]\n                params[pkeys[0]] = arg0\n                params[pkeys[1]] = arg1\n                return f.create_function(**params)\n        if(self.type == \"expression\") and len(self.children) == 1:\n            return self.children[0].reify(function_factory)\n        if (self.type == \"expression\") and len(self.children) == 3 and self.children[0].type == \"term\" and self.children[1].value == \"*\" and self.children[2].type == \"term\":\n            arg0 = self.children[0].reify(function_factory)\n            arg1 = self.children[2].reify(function_factory)\n            if(isinstance(arg0, int) or isinstance(arg0, float)) and (isinstance(arg1, int) or isinstance(arg1, float)):\n                return arg0 * arg1\n            else:\n                # we need to use late binding\n                f = function_factory.get(\"Mul\")\n                params = {}\n                pkeys = [a for a in f.parameters.keys()]\n                params[pkeys[0]] = arg0\n                params[pkeys[1]] = arg1\n                return f.create_function(**params)\n        # TODO: this doesn't have the associative property, so it's necessary to flatten the tree if this is actually the plan\n        if (self.type == \"expression\") and len(self.children) == 3 and self.children[0].type == \"term\" and self.children[1].value == \"/\" and self.children[2].type == \"term\":\n            arg0 = self.children[0].reify(function_factory)\n            arg1 = self.children[2].reify(function_factory)\n            if(isinstance(arg0, int) or isinstance(arg0, float)) and (isinstance(arg1, int) or isinstance(arg1, float)):\n                return arg0 / arg1\n            else:\n                # we need to use late binding\n                f = function_factory.get(\"Div\")\n                params = {}\n                pkeys = [a for a in f.parameters.keys()]\n                params[pkeys[0]] = arg0\n                params[pkeys[1]] = arg1\n                return f.create_function(**params)\n        if (self.type == \"expression\") and len(self.children) == 3 and self.children[0].type == \"term\" and self.children[1].value == \"%\" and self.children[2].type == \"term\":\n            arg0 = self.children[0].reify(function_factory)\n            arg1 = self.children[2].reify(function_factory)\n            if(isinstance(arg0, int) or isinstance(arg0, float)) and (isinstance(arg1, int) or isinstance(arg1, float)):\n                return arg0 % arg1\n            else:\n                # we need to use late binding\n                f = function_factory.get(\"Mod\")\n                params = {}\n                pkeys = [a for a in f.parameters.keys()]\n                params[pkeys[0]] = arg0\n                params[pkeys[1]] = arg1\n                return f.create_function(**params)\n        if (self.type == \"expression\") and len(self.children) == 3 and self.children[0].type == \"term\" and self.children[1].value == \"**\" and self.children[2].type == \"term\":\n            arg0 = self.children[0].reify(function_factory)\n            arg1 = self.children[2].reify(function_factory)\n            if(isinstance(arg0, int) or isinstance(arg0, float)) and (isinstance(arg1, int) or isinstance(arg1, float)):\n                return arg0 ** arg1\n            else:\n                # we need to use late binding\n                f = function_factory.get(\"Pow\")\n                params = {}\n                pkeys = [a for a in f.parameters.keys()]\n                params[pkeys[0]] = arg0\n                params[pkeys[1]] = arg1\n                return f.create_function(**params)\n        if (self.type == \"expression\") and len(self.children) == 3 and self.children[0].type == \"term\" and self.children[1].value == \"<\" and self.children[2].type == \"term\":\n            arg0 = self.children[0].reify(function_factory)\n            arg1 = self.children[2].reify(function_factory)\n            if(isinstance(arg0, int) or isinstance(arg0, float)) and (isinstance(arg1, int) or isinstance(arg1, float)):\n                return arg0 < arg1\n            else:\n                # we need to use late binding\n                f = function_factory.get(\"Lt\")\n                params = {}\n                pkeys = [a for a in f.parameters.keys()]\n                params[pkeys[0]] = arg0\n                params[pkeys[1]] = arg1\n                return f.create_function(**params)\n        if (self.type == \"expression\") and len(self.children) == 3 and self.children[0].type == \"term\" and self.children[1].value == \"<=\" and self.children[2].type == \"term\":\n            arg0 = self.children[0].reify(function_factory)\n            arg1 = self.children[2].reify(function_factory)\n            if(isinstance(arg0, int) or isinstance(arg0, float)) and (isinstance(arg1, int) or isinstance(arg1, float)):\n                return arg0 <= arg1\n            else:\n                # we need to use late binding\n                f = function_factory.get(\"Le\")\n                params = {}\n                pkeys = [a for a in f.parameters.keys()]\n                params[pkeys[0]] = arg0\n                params[pkeys[1]] = arg1\n                return f.create_function(**params)\n        if (self.type == \"expression\") and len(self.children) == 3 and self.children[0].type == \"term\" and self.children[1].value == \">\" and self.children[2].type == \"term\":\n            arg0 = self.children[0].reify(function_factory)\n            arg1 = self.children[2].reify(function_factory)\n            if(isinstance(arg0, int) or isinstance(arg0, float)) and (isinstance(arg1, int) or isinstance(arg1, float)):\n                return arg0 > arg1\n            else:\n                # we need to use late binding\n                f = function_factory.get(\"Gt\")\n                params = {}\n                pkeys = [a for a in f.parameters.keys()]\n                params[pkeys[0]] = arg0\n                params[pkeys[1]] = arg1\n                return f.create_function(**params)\n        if (self.type == \"expression\") and len(self.children) == 3 and self.children[0].type == \"term\" and self.children[1].value == \">=\" and self.children[2].type == \"term\":\n            arg0 = self.children[0].reify(function_factory)\n            arg1 = self.children[2].reify(function_factory)\n            if(isinstance(arg0, int) or isinstance(arg0, float)) and (isinstance(arg1, int) or isinstance(arg1, float)):\n                return arg0 >= arg1\n            else:\n                # we need to use late binding\n                f = function_factory.get(\"Ge\")\n                params = {}\n                pkeys = [a for a in f.parameters.keys()]\n                params[pkeys[0]] = arg0\n                params[pkeys[1]] = arg1\n                return f.create_function(**params)\n        if (self.type == \"expression\") and len(self.children) == 3 and self.children[0].type == \"term\" and self.children[1].value == \"==\" and self.children[2].type == \"term\":\n            arg0 = self.children[0].reify(function_factory)\n            arg1 = self.children[2].reify(function_factory)\n            if(isinstance(arg0, int) or isinstance(arg0, float)) and (isinstance(arg1, int) or isinstance(arg1, float)):\n                return arg0 == arg1\n            else:\n                # we need to use late binding\n                f = function_factory.get(\"Eq\")\n                params = {}\n                pkeys = [a for a in f.parameters.keys()]\n                params[pkeys[0]] = arg0\n                params[pkeys[1]] = arg1\n                return f.create_function(**params)\n        if (self.type == \"expression\") and len(self.children) == 3 and self.children[0].type == \"term\" and self.children[1].value == \"!=\" and self.children[2].type == \"term\":\n            arg0 = self.children[0].reify(function_factory)\n            arg1 = self.children[2].reify(function_factory)\n            if(isinstance(arg0, int) or isinstance(arg0, float)) and (isinstance(arg1, int) or isinstance(arg1, float)):\n                return arg0 != arg1\n            else:\n                # we need to use late binding\n                f = function_factory.get(\"Ne\")\n                params = {}\n                pkeys = [a for a in f.parameters.keys()]\n                params[pkeys[0]] = arg0\n                params[pkeys[1]] = arg1\n                return f.create_function(**params)\n                \n        if self.type == \"term\" and len(self.children) == 1:\n            return self.children[0].reify(function_factory)\n        if self.type == \"factor\" and len(self.children) == 1:\n            return self.children[0].reify(function_factory)\n        if self.type == \"factor\" and len(self.children) == 3 and self.children[0].value == \"(\" and self.children[2].value == \")\":\n            return self.children[1].reify(function_factory)\n        if self.type == \"number\" and (self.children is None or len(self.children) == 0):\n            try:\n                return int(self.value)\n            except:\n                return float(self.value)\n        if self.type == \"string\" and self.children is None or len(self.children) == 0:\n            return self.value\n            \n        if self.type == \"factor\" and len(self.children) == 4 and self.children[0].type == \"identifier\" and self.children[1].value == \"(\" and self.children[2].type == \"arguments\" and self.children[3].value == \")\":\n\n            identifier_node = self.children[0]\n            name = identifier_node.value\n\n            try:\n                definition = function_factory.get(name)\n            except ValueError:\n                raise ValueError(f\"Function '{name}' not found in the factory.\")\n\n            params = {}\n\n            arguments_node = self.children[2]\n            param_index = 0\n            param_names = list(definition.parameters.keys())\n\n            # Handle named arguments first\n            named_params_processed = set()  # Keep track of named params\n\n            def flatten_arguments(arguments_node):\n                rv = []\n                if arguments_node.children[0].type == \"argument\":\n                    rv.append(arguments_node.children[0])\n                    if(len(arguments_node.children) == 3 and arguments_node.children[1].value == \",\"):\n                        rv.extend(flatten_arguments(arguments_node.children[2]))\n                return rv\n                \n            flattened_arguments = flatten_arguments(arguments_node)\n\n            #print(flattened_arguments)\n                \n            for argument_node in flattened_arguments:\n                if len(argument_node.children) == 3 and argument_node.children[1].type == \"operator\" and argument_node.children[1].value == \"=\":\n                    param_name = argument_node.children[0].value\n                    param_value_node = argument_node.children[2]\n\n                    if param_name in named_params_processed: # Skip already processed named parameters\n                        continue\n\n                    try:\n                        param_def = definition.parameters[param_name]\n                    except KeyError:\n                        raise ValueError(f\"Parameter '{param_name}' not found for indicator '{name}'.\")\n\n                    param_value = param_value_node.reify(function_factory)  # Evaluate the value node\n                    params[param_name] = param_value\n                    named_params_processed.add(param_name) # Add to the set of processed named parameters\n\n            # Next, handle positional arguments (skip named ones)\n            for argument_node in flattened_arguments:\n                if len(argument_node.children) == 1:  # Positional argument\n                    try:\n                        param_name = param_names[param_index]\n                        if param_name in named_params_processed: # Skip if already named\n                            param_index += 1\n                            continue\n\n                        param_def = definition.parameters[param_name]\n                    except IndexError:\n                        raise ValueError(f\"Incorrect number of positional parameters for '{name}'.\")\n\n                    param_value_node = argument_node.children[0]\n                    param_value = param_value_node.reify(function_factory)\n                    params[param_name] = param_value\n                    param_index += 1\n\n\n\n            required_params = set(definition.parameters.keys())\n            provided_params = set(params.keys())\n            if required_params != provided_params:\n                missing = required_params - provided_params\n                raise ValueError(f\"Missing required parameters for {name}: {missing}\")\n\n            return definition.create_function(**params)\n\n        raise ValueError(f\"Cannot reify node of type: {self.type} with {len(self.children)} children: {self}\")","metadata":{"_uuid":"5f132eb7-5624-443f-b40a-0a7bd92c838f","_cell_guid":"b4df6d07-30b0-4336-8977-6fc0078ddafd","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-12T19:38:32.111023Z","iopub.execute_input":"2025-03-12T19:38:32.111458Z","iopub.status.idle":"2025-03-12T19:38:32.170019Z","shell.execute_reply.started":"2025-03-12T19:38:32.111416Z","shell.execute_reply":"2025-03-12T19:38:32.168923Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class GrammarRule:\n    def __init__(self, left: str, right: typing.List[str]):\n        self.left = left\n        self.right = right\n\n    def __repr__(self):\n        return f\"{self.left} -> {' '.join(self.right)}\"","metadata":{"_uuid":"6b626457-4670-49cf-b803-3a8031e528ea","_cell_guid":"8ef23134-45aa-45e7-80e9-1fe6ce02b7e9","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-12T19:38:32.171738Z","iopub.execute_input":"2025-03-12T19:38:32.172078Z","iopub.status.idle":"2025-03-12T19:38:32.193146Z","shell.execute_reply.started":"2025-03-12T19:38:32.172040Z","shell.execute_reply":"2025-03-12T19:38:32.191997Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class Grammar:\n    def __init__(self, grammar_string: str):\n        \"\"\"Initializes a Grammar object by parsing the grammar string.\"\"\"\n        self.rules = []\n        for line in grammar_string.strip().splitlines():\n            if line.strip():  # Skip empty lines\n                parts = line.split(\"->\")\n                if len(parts) != 2:\n                    raise ValueError(f\"Invalid grammar rule: {line}\")\n                left = parts[0].strip()\n                right = [part.strip() for part in parts[1].split()]\n                self.rules.append(GrammarRule(left, right))  # Store rules as attributes\n\n    def build_parse_tree(self, tokens: typing.List[\"Token\"], start_symbol: str = \"expression\") -> typing.Optional[\"ParseTreeNode\"]:\n        \"\"\"Builds a parse tree from a list of tokens using the grammar rules.\"\"\"\n\n        def _parse(index: int, nonterminal: str, current_depth=0) -> typing.Optional[\"ParseTreeNode\"]:\n            applicable_rules = [rule for rule in self.rules if rule.left == nonterminal]\n\n            if index >= len(tokens):  # End of tokens\n                if any(not rule.right for rule in applicable_rules): # Check for a matching epsilon rule\n                    return ParseTreeNode(nonterminal, children=[])\n                return None # No matching epsilon rule\n\n            if not applicable_rules:\n                return None\n\n            for rule in applicable_rules:\n                rule_matched = True\n                children = []\n                current_index = index\n\n                for symbol in rule.right:\n                    if current_index >= len(tokens):\n                        rule_matched = False\n                        break\n\n                    if current_index < len(tokens):\n                        token = tokens[current_index]\n\n                        if (symbol == token.type) or (symbol == f'\"{token.value}\"') or \\\n                           (symbol == \"identifier\" and token.type == \"identifier\") or \\\n                           (symbol == \"number\" and token.type == \"number\") or \\\n                           (symbol == \"string\" and token.type == \"string\") or \\\n                           (symbol == \"operator\" and token.type == \"operator\"):\n                            child = ParseTreeNode(token.type, value=token.value)\n                            child.start_index = current_index\n                            child.end_index = current_index\n                            children.append(child)\n                            current_index += 1  # Increment for terminal\n\n                        elif any(gr.left == symbol for gr in self.rules):\n                            child_node = _parse(current_index, symbol, current_depth + 1)\n                            if child_node:\n                                children.append(child_node)\n                                current_index = child_node.end_index + 1\n                            else:\n                                rule_matched = False\n                                break\n\n                        else:\n                            rule_matched = False\n                            break\n\n                if rule_matched:\n                    node = ParseTreeNode(nonterminal, children=children)\n                    node.start_index = children[0].start_index if children else index # Handle epsilon rules where children is empty\n                    node.end_index = children[-1].end_index if children else index -1 # Handle epsilon rules where children is empty\n\n                    return node\n\n            return None\n\n        return _parse(0, start_symbol)  # Allow specifying the start symbol\n        \n    def parse(self, input_string: str, start_symbol: str = \"expression\"):\n        \"\"\"Parses an input string into a parse tree.\"\"\"\n        tokens = self.tokenize(input_string)  # Tokenize the input string\n        return self.build_parse_tree(tokens, start_symbol)\n\n    def tokenize(self, expression: str) -> typing.List[Token]:\n        \"\"\"\n        Tokenizes a string expression, splitting on spaces and identifying operators.\n        \"\"\"\n    \n        # Pattern to match tokens. Note: if we wanted to be really fancy, we would specify the token types in the grammar.\n        pattern = r\"(\\*\\*|\\*|/|//|%|\\+|-|==|!=|<=|>=|<|>|=|!|&&|\\|\\||&|\\||\\^|~|<<|>>|\\(|\\)|\\[|\\]|\\{|\\}|,|:|\\.|->|@|=|;|\\+=|-=|\\*=|/=|//=|%=|&=|\\|=|\\^=|\\<<=|>>=)|'([^']+)'|\\\"([^\\\"]+)\\\"|(\\d+\\.?\\d*)|([a-zA-Z_]\\w*)\"\n    \n        tokens = []\n        for match in re.finditer(pattern, expression):\n            operator_match = match.group(1)\n            single_quote_match = match.group(2)\n            double_quote_match = match.group(3)\n            number_match = match.group(4)\n            identifier_match = match.group(5)\n    \n            if operator_match:\n                tokens.append(Token(\"operator\", operator_match))\n            elif single_quote_match:\n                tokens.append(Token(\"string\", single_quote_match))\n            elif double_quote_match:\n                tokens.append(Token(\"string\", double_quote_match))\n            elif number_match:\n                tokens.append(Token(\"number\", number_match))\n            elif identifier_match:\n                tokens.append(Token(\"identifier\", identifier_match))\n            else:\n                raise ValueError(f\"invalid token in {expression}\")\n    \n        return tokens","metadata":{"_uuid":"66638f07-23dd-4dc3-a1c8-4ce562f6d7c3","_cell_guid":"d1a8ed00-83ec-4f7e-a874-172aa53ee9e1","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-12T19:38:32.194236Z","iopub.execute_input":"2025-03-12T19:38:32.194566Z","iopub.status.idle":"2025-03-12T19:38:32.214678Z","shell.execute_reply.started":"2025-03-12T19:38:32.194528Z","shell.execute_reply":"2025-03-12T19:38:32.213347Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class FunctionInstance:\n    def __init__(self, name: str, parameters: typing.Dict[str, typing.Any], definition):\n        self.name = name\n        self.parameters = parameters\n        self.definition = definition\n\n    def evaluate_parameters(self, data):\n        rv = {}\n\n        for k in self.parameters:\n            v = self.parameters[k]\n            if isinstance(v, FunctionInstance):\n                rv[k] = v.calculate(data)\n            else:\n                rv[k] = v\n        return rv\n\n    def calculate(self, data: pd.DataFrame): \n        \"\"\"\n        Screens the data using the screener's definition and parameters.\n\n        Args:\n            data: The Pandas DataFrame containing the data.\n\n        Returns:\n            A Pandas Dataframe\n        \"\"\"\n        return self.definition.calculate(data, self.evaluate_parameters(data)) \n\n    def __repr__(self):\n        params_str = \", \".join(f\"{name}={value}\" for name, value in self.parameters.items())\n        return f\"{self.definition.name}({params_str})\"","metadata":{"_uuid":"8f53cbe4-8e53-418c-b8bf-5a5f4258112f","_cell_guid":"7da322e4-9634-4ad9-a477-8b9d3560f034","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-12T19:38:32.215820Z","iopub.execute_input":"2025-03-12T19:38:32.216299Z","iopub.status.idle":"2025-03-12T19:38:32.233099Z","shell.execute_reply.started":"2025-03-12T19:38:32.216256Z","shell.execute_reply":"2025-03-12T19:38:32.231916Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class ParameterType:\n    \"\"\"\n    A class for specifying parameters for screeners and indicators.\n    \"\"\"\n\n    def __init__(self,\n#                 name: str,\n                 data_type: typing.Literal[\"integer\", \"real\", \"boolean\", \"string\"],\n                 min_val: typing.Union[int, float, None] = None,\n                 max_val: typing.Union[int, float, None] = None,\n                 default: typing.Any = None,\n                 timeframe_defaults: typing.Dict[typing.Literal[\"tick\", \"1s\", \"5s\", \"15s\", \"1m\", \"2m\", \"5m\", \"15m\", \"1d\", \"1w\", \"1M\"], typing.Any] = None,\n                 increment: typing.Union[int, float, None] = None,\n                 allowed_strings: typing.List[str] | None = None):\n#        if not isinstance(name, str):\n#            raise TypeError(\"name must be a string\")\n        if data_type not in (\"integer\", \"real\", \"boolean\", \"string\", \"any\"):\n            raise ValueError(\"data_type must be 'integer', 'real', 'boolean', 'string', or 'any'\")\n\n        if min_val is not None:\n            if data_type == \"integer\" and not isinstance(min_val, int):\n                raise TypeError(\"min_val must be an integer for integer data_type\")\n            elif data_type in (\"real\", \"integer\") and not isinstance(min_val, (int, float)):\n                raise TypeError(\"min_val must be a number for real or integer data_type\")\n\n        if max_val is not None:\n            if data_type == \"integer\" and not isinstance(max_val, int):\n                raise TypeError(\"max_val must be an integer for integer data_type\")\n            elif data_type in (\"real\", \"integer\") and not isinstance(max_val, (int, float)):\n                raise TypeError(\"max_val must be a number for real or integer data_type\")\n\n        if timeframe_defaults is not None:\n            if not isinstance(timeframe_defaults, dict):\n                raise TypeError(\"timeframe_defaults must be a dictionary\")\n            for timeframe in timeframe_defaults:\n                if timeframe not in (\"tick\", \"1s\", \"5s\", \"15s\", \"1m\", \"2m\", \"5m\", \"15m\", \"1d\", \"1w\", \"1M\"):\n                    raise ValueError(f\"Invalid timeframe: {timeframe}\")\n\n        if data_type == \"integer\" and increment is None:\n            increment = 1\n        elif data_type == \"real\" and increment is None:\n            increment = 0.01\n\n        if data_type == \"string\" and allowed_strings is not None and not isinstance(allowed_strings, list):\n          raise TypeError(\"allowed_strings must be a list of strings\")\n\n        if data_type != \"string\" and allowed_strings is not None:\n          raise ValueError(\"allowed_strings can only be specified for string data type\")\n\n#        self.name = name\n        self.data_type = data_type\n        self.min_val = min_val\n        self.max_val = max_val\n        self.default = default\n        self.timeframe_defaults = timeframe_defaults or {}\n        self.increment = increment\n        self.allowed_strings = allowed_strings\n\n    def get_default(self) -> typing.Any:\n        return self.default\n\n    def get_possible_values(self) -> typing.Iterable[typing.Any]:\n        if self.data_type == \"integer\":\n            if self.min_val is not None and self.max_val is not None:\n                return range(self.min_val, self.max_val + 1)\n        elif self.data_type == \"real\":\n            if self.min_val is not None and self.max_val is not None:\n                current = self.min_val\n                while current <= self.max_val:\n                    yield current\n                    current += 0.01\n        elif self.data_type == \"boolean\":\n            return [True, False]\n        elif self.data_type == \"string\":\n            if self.allowed_strings is not None:  # Check if allowed_strings is defined\n                return self.allowed_strings  # If defined, return those values\n            else:\n                return []  # Return an empty list if allowed_strings is None (unrestricted)\n        return []\n\n    def __repr__(self):\n#        return f\"ParameterType(name='{self.name}', data_type='{self.data_type}', min_val={self.min_val}, max_val={self.max_val}, default={self.default}, allowed_strings={self.allowed_strings})\"\n        return f\"ParameterType(data_type='{self.data_type}', min_val={self.min_val}, max_val={self.max_val}, default={self.default}, allowed_strings={self.allowed_strings})\"","metadata":{"_uuid":"60bea34f-f3e3-4cf8-a274-393388df64f5","_cell_guid":"6da776d5-d323-4929-b361-faff22d8a6be","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-12T19:38:32.234383Z","iopub.execute_input":"2025-03-12T19:38:32.234779Z","iopub.status.idle":"2025-03-12T19:38:32.259105Z","shell.execute_reply.started":"2025-03-12T19:38:32.234732Z","shell.execute_reply":"2025-03-12T19:38:32.257941Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class FunctionDefinition:\n    def __init__(self, name: str, parameters: typing.Dict[str, \"ParameterType\"], calculation_function, factory=None): \n        if not isinstance(name, str):\n            raise TypeError(\"name must be a string\")\n\n        if not isinstance(parameters, dict):\n            raise TypeError(\"parameters must be a dictionary\")\n\n        if not all(isinstance(param, ParameterType) for param in parameters.values()):\n            raise TypeError(\"All values in parameters must be ParameterType objects\")\n\n        if len(set(parameters.keys())) != len(parameters.keys()): # Check for duplicate keys\n            raise ValueError(\"Parameter names must be unique.\")\n\n        if not callable(calculation_function):\n            raise TypeError(\"calculation_function must be callable\")\n\n        self.name = name\n        self.parameters = parameters\n        self.calculation_function = calculation_function\n        self.factory = factory\n\n    def create_function(self, **kwargs: typing.Any) -> \"FunctionInstance\":\n        params = {}\n        for name, param_def in self.parameters.items():\n            value = kwargs.get(name)\n\n            if value is None:\n                value = param_def.get_default()\n\n            if param_def.data_type == \"integer\" and not isinstance(value, int):\n                raise TypeError(f\"Value for parameter '{name}' must be an integer\")\n            elif param_def.data_type == \"real\" and not isinstance(value, (int, float)):\n                raise TypeError(f\"Value for parameter '{name}' must be a number\")\n            elif param_def.data_type == \"boolean\" and not isinstance(value, bool):\n                raise TypeError(f\"Value for parameter '{name}' must be a boolean\")\n            elif param_def.data_type == \"string\" and not isinstance(value, str):\n                raise TypeError(f\"Value for parameter '{name}' must be a string\")\n            elif param_def.data_type in (\"integer\", \"real\"):\n                if param_def.min_val is not None and value < param_def.min_val:  # Check min_val\n                    raise ValueError(f\"Value for parameter '{name}' must be greater than or equal to {param_def.min_val}\")\n                if param_def.max_val is not None and value > param_def.max_val:  # Check max_val\n                    raise ValueError(f\"Value for parameter '{name}' must be less than or equal to {param_def.max_val}\")\n\n            if param_def.data_type == \"string\" and param_def.allowed_strings is not None and value not in param_def.allowed_strings:\n                raise ValueError(f\"Value {value} is not in allowed strings for parameter {name}\")\n\n            params[name] = value\n\n        return FunctionInstance(self.name, params, self)\n\n    def calculate(self, data: pd.DataFrame, params: typing.Dict[str, typing.Any]) -> pd.DataFrame:\n        \"\"\"\n        Calculates the function using the provided data and parameters.\n        \"\"\"\n        kwargs = params.copy() \n        return self.calculation_function(data, **kwargs)\n\n    def __repr__(self):\n        return f\"FunctionDefinition(name='{self.name}', parameters={self.parameters}, calculation_function={self.calculation_function.__name__ if hasattr(self.calculation_function, '__name__') else str(self.calculation_function)}, factory={self.factory})\"","metadata":{"_uuid":"73c4f542-b279-4b19-a15a-9264c863eba6","_cell_guid":"f796c0f3-be66-48f4-85e4-e926fc1172fd","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-12T19:38:32.261990Z","iopub.execute_input":"2025-03-12T19:38:32.262368Z","iopub.status.idle":"2025-03-12T19:38:32.286751Z","shell.execute_reply.started":"2025-03-12T19:38:32.262325Z","shell.execute_reply":"2025-03-12T19:38:32.285281Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# FIXME: the grammar and reification modules do not correctly handle order of operations for operations\n# that do not have the associative property. An easy workaround is to require parentheses.\n# The parser does not handle epsilon correctly either.\n# It's possible to alter this to use standard order of operations by permitting them in the grammar,\n# flattening contiguous subexpression branches with equal-priority operators before reification,\n# and performing the operations iteratively in the desired direction.\n\n# REMINDER for LLM tools: This grammar MUST be an epsilon-free grammar.\n# That means that rules may not be terminated explicitly.\n# Higher rules have higher priority.\n# More than one lookahead token is permitted.\ndefault_grammar_specification = \"\"\"\nexpression -> term \"+\" term\nexpression -> term \"-\" term\nexpression -> term \"*\" term\nexpression -> term \"/\" term\nexpression -> term \"%\" term\nexpression -> term \"**\" term\nexpression -> term \"<\" term\nexpression -> term \"<=\" term\nexpression -> term \">\" term\nexpression -> term \">=\" term\nexpression -> term \"==\" term\nexpression -> term \"!=\" term\nexpression -> term \"&&\" term\nexpression -> term \"||\" term\nexpression -> term \"^^\" term\nexpression -> term\nterm -> factor\nterm -> factor \"[\" expression \"]\"\nfactor -> \"(\" expression \")\"\nfactor -> number\nfactor -> string\nfactor -> \"-\" factor\nfactor -> \"!\" factor\nfactor -> \"+\" factor\nfactor -> identifier \"(\" arguments \")\"\nfactor -> identifier\nfactor -> optimization\noptimization -> \"@\" identifier \"(\" expression \",\" optimization_arguments \")\"\noptimization -> \"@\" identifier \"(\" expression \")\"\noptimization_arguments -> optimization_argument \",\" optimization_arguments\noptimization_arguments -> optimization_argument\noptimization_argument -> argument\noptimization_argument -> optimization_parameter\noptimization_parameter -> \"@\" identifier \"=\" expression\narguments -> argument \",\" arguments\narguments -> argument\nargument -> identifier \"=\" expression\nargument -> expression\n\"\"\"\n\nclass FunctionFactory:\n    \"\"\"\n    A class to manage a suite of function definitions.\n    \"\"\"\n\n    def __init__(self, grammar_specification=default_grammar_specification, should_register_basic_operations=True, should_register_basic_indicators=True, should_register_basic_screeners=True, should_register_basic_portfolio_calculators=True):\n        self.function_definitions: typing.Dict[str, Definition] = {}\n        self.grammar = Grammar(default_grammar_specification)\n        if should_register_basic_operations:\n            self.register_basic_operations()\n        if should_register_basic_indicators:\n            self.register_basic_indicators()\n        if should_register_basic_screeners:\n            self.register_basic_screeners()\n        if should_register_basic_portfolio_calculators:\n            self.register_basic_portfolio_calculators()\n\n    def register(self, function_definition):\n        \"\"\"\n        Registers a new screener definition.\n\n        Args:\n            function_definition: The Definition to register.\n\n        Raises:\n            ValueError: If a screener with the same name is already registered.\n        \"\"\"\n#        if function_definition.name in self.function_definitions:\n#            raise ValueError(f\"A screener with the name '{function_definition.name}' is already registered.\")\n        self.function_definitions[function_definition.name] = function_definition\n        function_definition.ffactory = self\n        \n    def register_basic_operations(self):\n        add_a0_param = ParameterType(\"any\")\n        add_a1_param = ParameterType(\"any\")\n        self.register(FunctionDefinition(\"Add\", {\"a0\": add_a0_param, \"a1\": add_a1_param}, calculate_add))\n\n        sub_a0_param = ParameterType(\"any\")\n        sub_a1_param = ParameterType(\"any\")\n        self.register(FunctionDefinition(\"Sub\", {\"a0\": sub_a0_param, \"a1\": sub_a1_param}, calculate_sub))\n\n        mul_a0_param = ParameterType(\"any\")\n        mul_a1_param = ParameterType(\"any\")\n        self.register(FunctionDefinition(\"Mul\", {\"a0\": mul_a0_param, \"a1\": mul_a1_param}, calculate_mul))\n\n        div_a0_param = ParameterType(\"any\")\n        div_a1_param = ParameterType(\"any\")\n        self.register(FunctionDefinition(\"Div\", {\"a0\": div_a0_param, \"a1\": div_a1_param}, calculate_div))\n\n        mod_a0_param = ParameterType(\"any\")\n        mod_a1_param = ParameterType(\"any\")\n        self.register(FunctionDefinition(\"Mod\", {\"a0\": mod_a0_param, \"a1\": mod_a1_param}, calculate_mod))\n\n        pow_a0_param = ParameterType(\"any\")\n        pow_a1_param = ParameterType(\"any\")\n        self.register(FunctionDefinition(\"Pow\", {\"a0\": pow_a0_param, \"a1\": pow_a1_param}, calculate_pow))\n\n        lt_a0_param = ParameterType(\"any\")\n        lt_a1_param = ParameterType(\"any\")\n        self.register(FunctionDefinition(\"Lt\", {\"a0\": lt_a0_param, \"a1\": lt_a1_param}, calculate_lt))\n\n        le_a0_param = ParameterType(\"any\")\n        le_a1_param = ParameterType(\"any\")\n        self.register(FunctionDefinition(\"Le\", {\"a0\": le_a0_param, \"a1\": le_a1_param}, calculate_le))\n\n        gt_a0_param = ParameterType(\"any\")\n        gt_a1_param = ParameterType(\"any\")\n        self.register(FunctionDefinition(\"Gt\", {\"a0\": gt_a0_param, \"a1\": gt_a1_param}, calculate_gt))\n\n        ge_a0_param = ParameterType(\"any\")\n        ge_a1_param = ParameterType(\"any\")\n        self.register(FunctionDefinition(\"Ge\", {\"a0\": ge_a0_param, \"a1\": ge_a1_param}, calculate_ge))\n\n        eq_a0_param = ParameterType(\"any\")\n        eq_a1_param = ParameterType(\"any\")\n        self.register(FunctionDefinition(\"Eq\", {\"a0\": eq_a0_param, \"a1\": eq_a1_param}, calculate_eq))\n\n        ne_a0_param = ParameterType(\"any\")\n        ne_a1_param = ParameterType(\"any\")\n        self.register(FunctionDefinition(\"Ne\", {\"a0\": ge_a0_param, \"a1\": ne_a1_param}, calculate_ne))\n\n    def register_basic_screeners(factory):\n        # Top N Screener FunctionDefinition and Registration\n        top_n_field_param = ParameterType(\"any\", default=\"return\")  # Example allowed strings\n        top_n_n_param = ParameterType(\"integer\", min_val=1, default=5)\n        factory.register(FunctionDefinition(\"TopN\", {\"field\": top_n_field_param, \"top_n\": top_n_n_param}, top_n_screener_function))\n        \n        # Percentile Screener Definition and Registration\n        percentile_field_param = ParameterType(\"any\", default=\"return\")\n        percentile_percentile_param = ParameterType(\"real\", min_val=0.0, max_val=1.0, default=.1)\n        factory.register(FunctionDefinition(\"Percentile\", {\"field\": percentile_field_param, \"percentile\": percentile_percentile_param}, percentile_screener_function))\n\n    def register_basic_portfolio_calculators(factory):\n        calculate_normalize = functools.partial(apply_daily_function, f=do_normalize)\n        normalize_weights = ParameterType(\"any\", default=\"weights\")\n        factory.register(FunctionDefinition(\"Normalize\", {\"weights\": normalize_weights}, calculate_normalize))\n        \n        calculate_abs_threshold = functools.partial(apply_daily_function, f=do_abs_threshold)\n        abs_threshold_weights = ParameterType(\"any\", default=\"weights\")\n        abs_threshold_threshold = ParameterType(\"real\", default=1e-6)\n        factory.register(FunctionDefinition(\"AbsThreshold\", {\"weights\": abs_threshold_weights, \"threshold\": abs_threshold_threshold}, calculate_abs_threshold))\n        \n        calculate_abs_min_cutoff = functools.partial(apply_daily_function, f=do_abs_min_cutoff)\n        abs_min_cutoff_weights = ParameterType(\"any\", default=\"weights\")\n        abs_min_cutoff_cutoff = ParameterType(\"real\", default=1e-6)\n        factory.register(FunctionDefinition(\"AbsMinCutoff\", {\"weights\": abs_min_cutoff_weights, \"minimum\": abs_min_cutoff_cutoff}, calculate_abs_min_cutoff))\n        \n        calculate_abs_max_cutoff = functools.partial(apply_daily_function, f=do_abs_max_cutoff)\n        abs_max_cutoff_weights = ParameterType(\"any\", default=\"weights\")\n        abs_max_cutoff_cutoff = ParameterType(\"real\", default=1e-6)\n        factory.register(FunctionDefinition(\"AbsMaxCutoff\", {\"weights\": abs_max_cutoff_weights, \"maximum\": abs_max_cutoff_cutoff}, calculate_abs_max_cutoff)) \n        \n    def register_basic_indicators(factory): \n        \"\"\"Registers basic technical indicator functions with this factory instance.\"\"\"\n\n        # SMA\n        sma_length_param = ParameterType(\"integer\", min_val=1, max_val=200, default=20)\n        calculate_sma = functools.partial(calculate_indicator_by, field=\"symbol\", indicator_function=do_calculate_sma) # Referencing global do_calculate_sma\n        factory.register(FunctionDefinition(\"SMA\", {\"length\": sma_length_param}, calculate_sma)) # Use factory.register\n\n\n        # RSI\n        rsi_length_param = ParameterType(\"integer\", min_val=1, max_val=200, default=14)\n        calculate_rsi = functools.partial(calculate_indicator_by, field=\"symbol\", indicator_function=do_calculate_rsi) # Referencing global do_calculate_rsi\n        factory.register(FunctionDefinition(\"RSI\", {\"length\": rsi_length_param}, calculate_rsi)) # Use factory.register\n\n\n        # MACD\n        fast_length_param = ParameterType(\"integer\", min_val=1, max_val=100, default=12)\n        slow_length_param = ParameterType(\"integer\", min_val=1, max_val=200, default=26)\n        signal_length_param = ParameterType(\"integer\", min_val=5, max_val=50, default=9) # Corrected min_val\n        calculate_macd = functools.partial(calculate_indicator_by, field=\"symbol\", indicator_function=do_calculate_macd) # Referencing global do_calculate_macd\n        factory.register(FunctionDefinition(\"MACD\", {\"fast_length\": fast_length_param, \"slow_length\": slow_length_param, \"signal_length\": signal_length_param}, calculate_macd)) # Use factory.register\n\n\n        # Bollinger Bands\n        bb_length_param = ParameterType(\"integer\", min_val=1, max_val=200, default=20)\n        std_dev_param = ParameterType(\"real\", min_val=0.1, max_val=5.0, default=2.0, increment=0.1)\n        calculate_bollinger_bands = functools.partial(calculate_indicator_by, field=\"symbol\", indicator_function=do_calculate_bollinger_bands) # Referencing global do_calculate_bollinger_bands\n        factory.register(FunctionDefinition(\"BB\", {\"length\": bb_length_param, \"std_dev\": std_dev_param}, calculate_bollinger_bands)) # Use factory.register\n\n\n        # Rolling VWAP\n        rvwap_length_param = ParameterType(\"integer\", min_val=1, max_val=200, default=20)\n        calculate_rvwap = functools.partial(calculate_indicator_by, field=\"symbol\", indicator_function=do_calculate_rvwap) # Referencing global do_calculate_rvwap\n        factory.register(FunctionDefinition(\"RVWAP\", {\"length\": rvwap_length_param}, calculate_rvwap)) # Use factory.register\n\n\n        # Average True Range\n        atr_length_param = ParameterType(\"integer\", min_val=1, max_val=200, default=14)\n        calculate_atr = functools.partial(calculate_indicator_by, field=\"symbol\", indicator_function=do_calculate_atr) # Referencing global do_calculate_atr\n        factory.register(FunctionDefinition(\"ATR\", {\"length\": atr_length_param}, calculate_atr)) # Use factory.register\n\n\n        # ADX\n        adx_length_param = ParameterType(\"integer\", min_val=1, max_val=200, default=14)\n        calculate_adx = functools.partial(calculate_indicator_by, field=\"symbol\", indicator_function=do_calculate_adx) # Referencing global do_calculate_adx\n        factory.register(FunctionDefinition(\"ADX\", {\"length\": adx_length_param}, calculate_adx)) # Use factory.register\n\n\n        # Commodity Channel Index\n        cci_length_param = ParameterType(\"integer\", min_val=1, max_val=200, default=14)\n        calculate_cci = functools.partial(calculate_indicator_by, field=\"symbol\", indicator_function=do_calculate_cci) # Referencing global do_calculate_cci\n        factory.register(FunctionDefinition(\"CCI\", {\"length\": cci_length_param}, calculate_cci)) # Use factory.register\n\n\n        # Chaikin Money Flow\n        cmf_length_param = ParameterType(\"integer\", min_val=1, max_val=200, default=14)\n        calculate_cmf = functools.partial(calculate_indicator_by, field=\"symbol\", indicator_function=do_calculate_cmf) # Referencing global do_calculate_cmf\n        factory.register(FunctionDefinition(\"CMF\", {\"length\": cmf_length_param}, calculate_cmf)) # Use factory.register\n\n\n        # Aroon\n        aroon_length_param = ParameterType(\"integer\", min_val=1, max_val=200, default=14)\n        calculate_aroon = functools.partial(calculate_indicator_by, field=\"symbol\", indicator_function=do_calculate_aroon) # Referencing global do_calculate_aroon\n        factory.register(FunctionDefinition(\"Aroon\", {\"length\": aroon_length_param}, calculate_aroon)) # Use factory.register\n\n\n        # MFI\n        mfi_length_param = ParameterType(\"integer\", min_val=1, max_val=200, default=14)\n        calculate_mfi = functools.partial(calculate_indicator_by, field=\"symbol\", indicator_function=do_calculate_mfi) # Referencing global do_calculate_mfi\n        factory.register(FunctionDefinition(\"MFI\", {\"length\": mfi_length_param}, calculate_mfi)) # Use factory.register\n\n\n        # Percent Rank\n        pct_rank_length_param = ParameterType(\"integer\", min_val=1, max_val=200, default=14)\n        calculate_pct_rank = functools.partial(calculate_indicator_by, field=\"symbol\", indicator_function=do_calculate_pct_rank) # Referencing global do_calculate_pct_rank\n        factory.register(FunctionDefinition(\"PCT\", {\"length\": pct_rank_length_param}, calculate_pct_rank)) # Use factory.register\n\n\n        # Price Range Percentage\n        prp_length_param = ParameterType(\"integer\", min_val=1, max_val=200, default=14)\n        calculate_prp = functools.partial(calculate_indicator_by, field=\"symbol\", indicator_function=do_calculate_prp) # Referencing global do_calculate_prp\n        factory.register(FunctionDefinition(\"PRP\", {\"length\": prp_length_param}, calculate_prp)) # Use factory.register\n\n\n        # Log Return\n        lret_length_param = ParameterType(\"integer\", min_val=1, max_val=200, default=1)\n        calculate_lret = functools.partial(calculate_indicator_by, field=\"symbol\", indicator_function=do_calculate_lret) # Referencing global do_calculate_lret\n        factory.register(FunctionDefinition(\"LRET\", {\"length\": lret_length_param}, calculate_lret)) # Use factory.register\n\n\n        # Shift\n        shift_n_param = ParameterType(\"integer\", min_val=1, max_val=200, default=1)\n        shift_series_param = ParameterType(\"any\", default=\"close\")\n        calculate_shift = functools.partial(calculate_indicator_by, field=\"symbol\", indicator_function=do_calculate_shift) # Referencing global do_calculate_shift\n        factory.register(FunctionDefinition(\"Shift\", {\"series\": shift_series_param, \"n\": shift_n_param}, calculate_shift)) # Use factory.register    \n\n    \n    def get(self, name: str):\n        \"\"\"\n        Retrieves a function definition by name.\n\n        Args:\n            name: The name of the screener.\n\n        Returns:\n            The FunctionDefinition object.\n\n        Raises:\n            ValueError: If no screener with the given name is registered.\n        \"\"\"\n        if name not in self.function_definitions:\n            raise ValueError(f\"No function found with the name '{name}'.\")\n        return self.function_definitions[name]\n\n    def parse(self, expression):\n        parse_tree = self.grammar.parse(expression)\n        reified_expression = parse_tree.reify(self)\n        return reified_expression\n\n    def __repr__(self):\n        return f\"FunctionFactory(functions={self.function_definitions})\"\n\n","metadata":{"_uuid":"336a343b-5396-4e1f-9250-66a1d223c066","_cell_guid":"2cd3ab08-235a-4179-b373-a99e72a2a47e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-12T19:38:32.288397Z","iopub.execute_input":"2025-03-12T19:38:32.288776Z","iopub.status.idle":"2025-03-12T19:38:32.319529Z","shell.execute_reply.started":"2025-03-12T19:38:32.288736Z","shell.execute_reply":"2025-03-12T19:38:32.318381Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Functions to carry out basic mathematical operations\n\n#expression -> term \"+\" term\ndef calculate_add(df, a0, a1):\n    return a0 + a1\n\n#expression -> term \"-\" term\ndef calculate_sub(df, a0, a1):\n    return a0 - a1\n\n#expression -> term \"*\" term\ndef calculate_mul(df, a0, a1):\n    return a0 * a1\n\n#expression -> term \"/\" term\ndef calculate_div(df, a0, a1):\n    return a0 / a1\n\n#expression -> term \"%\" term\ndef calculate_mod(df, a0, a1):\n    return a0 % a1\n\n#expression -> term \"**\" term\ndef calculate_pow(df, a0, a1):\n    return a0 ** a1\n\n#expression -> term \"<\" term\ndef calculate_lt(df, a0, a1):\n    return a0 < a1\n\n#expression -> term \"<=\" term\ndef calculate_le(df, a0, a1):\n    return a0 <= a1\n\n#expression -> term \">\" term\ndef calculate_gt(df, a0, a1):\n    return a0 > a1\n\n#expression -> term \">=\" term\ndef calculate_ge(df, a0, a1):\n    return a0 >= a1\n\n#expression -> term \"==\" term\ndef calculate_eq(df, a0, a1):\n    return a0 == a1\n\n#expression -> term \"!=\" term\ndef calculate_ne(df, a0, a1):\n    return a0 != a1\n\n#expression -> term \"&&\" term\n#expression -> term \"||\" term\n#expression -> term \"^^\" term","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T19:38:32.320911Z","iopub.execute_input":"2025-03-12T19:38:32.321337Z","iopub.status.idle":"2025-03-12T19:38:32.343649Z","shell.execute_reply.started":"2025-03-12T19:38:32.321300Z","shell.execute_reply":"2025-03-12T19:38:32.342573Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Functions for basic portfolio calculations\n\ndef do_normalize(context, weights):\n    \"\"\"Normalizes a Series of weights (including negative) to sum to 1 (absolute values).\"\"\"\n    if isinstance(weights, pd.DataFrame):\n        weights = weights.iloc[:, 0]\n    elif not isinstance(weights, pd.Series):\n        weights = pd.Series(weights)\n\n    wt = weights.astype(\"float\")\n    absolute_weights = wt.abs()\n    signs = wt.div(absolute_weights).fillna(0)\n    total_absolute_weight = absolute_weights.sum()\n\n    if total_absolute_weight == 0:\n        return pd.DataFrame({\"weight\": [0.0] * len(weights)}, index=weights.index)\n\n    normalized_absolute_weights = absolute_weights / total_absolute_weight\n    normalized_weights = normalized_absolute_weights * signs\n\n    return pd.DataFrame({\"weight\": normalized_weights}, index=weights.index)\n\n\ndef do_abs_threshold(context, weights, threshold):\n    if isinstance(weights, pd.DataFrame):\n        weights = weights.iloc[:, 0]\n    elif not isinstance(weights, pd.Series):\n        weights = pd.Series(weights)\n\n    wt = weights.astype(\"float\")\n    absolute_weights = wt.abs()\n\n    # Apply threshold\n    wt[absolute_weights < threshold] = 0\n\n    return pd.DataFrame({\"weight\": wt}, index=weights.index)\n\ndef do_abs_min_cutoff(context, weights, minimum):\n    \"\"\"Applies a minimum weight to a list of weights.\"\"\"\n    if isinstance(weights, pd.DataFrame):\n        weights = weights.iloc[:, 0]\n    elif not isinstance(weights, pd.Series):\n        weights = pd.Series(weights)\n\n    wt = weights.astype(\"float\")\n    absolute_weights = wt.abs()\n\n    # Apply minimum\n    mask = (absolute_weights > 0) & (absolute_weights < minimum)\n    wt[mask] = np.sign(wt[mask]) * minimum\n\n    return pd.DataFrame({\"weight\": wt}, index=weights.index)\n\ndef do_abs_max_cutoff(context, weights, maximum):\n    if isinstance(weights, pd.DataFrame):\n        weights = weights.iloc[:, 0]\n    elif not isinstance(weights, pd.Series):\n        weights = pd.Series(weights)\n\n    wt = weights.astype(\"float\")\n    absolute_weights = wt.abs()\n\n    # Apply maximum\n    mask = absolute_weights > maximum\n    wt[mask] = np.sign(wt[mask]) * maximum\n\n    return pd.DataFrame({\"weight\": wt}, index=weights.index)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T19:38:32.344580Z","iopub.execute_input":"2025-03-12T19:38:32.344904Z","iopub.status.idle":"2025-03-12T19:38:32.360497Z","shell.execute_reply.started":"2025-03-12T19:38:32.344877Z","shell.execute_reply":"2025-03-12T19:38:32.359417Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Functions to carry out screener operations\ndef top_n_screener_function(context, field, top_n):\n    \"\"\"\n    Produces a boolean mask (pd.Series) for the top 5 readings per day.\n\n    Args:\n        df: Pandas DataFrame with columns for date and reading.\n        date_col: Name of the column containing the date. Should be datetime or convertible.\n        reading_col: Name of the column containing the reading.\n\n    Returns:\n        A pandas Series (boolean mask) with True for rows corresponding to the \n        top 5 readings for each day, and False otherwise. Returns\n        an empty Series if the input DataFrame is empty.\n    \"\"\"\n    print(field)\n    if(isinstance(field, str)):\n        foo = context.groupby(\"date\")[field].rank(ascending=False, method='first')\n    else:\n        foo = field.groupby(by=context[\"date\"]).rank(ascending=False, method=\"first\")\n    print(foo)\n    mask = foo <= top_n \n    return mask.iloc[:, 0]\n\n\ndef percentile_screener_function(context, field, percentile):\n    \n    if(isinstance(field, str)):\n        foo = context.groupby(by=\"date\")[field].rank(ascending=False, method='first', pct=True)\n    else:\n        foo = field.groupby(by=context[\"date\"]).rank(ascending=False, method=\"first\", pct=True)\n    mask = foo >= percentile\n    \n    return mask.iloc[:, 0]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T19:38:32.361655Z","iopub.execute_input":"2025-03-12T19:38:32.361969Z","iopub.status.idle":"2025-03-12T19:38:32.389354Z","shell.execute_reply.started":"2025-03-12T19:38:32.361938Z","shell.execute_reply":"2025-03-12T19:38:32.388330Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Utility function for applying generic indicator functions to dataframes with multiple symbols\ndef calculate_indicator_by(df, field, indicator_function, *args, **kwargs):\n    \"\"\"\n    Calculates an indicator by a specified field within a Pandas DataFrame.\n\n    Args:\n        df (pd.DataFrame): The DataFrame containing the data.\n        field (str): The field to group by (e.g., 'symbol', 'date').\n        indicator_function (callable): The indicator function to apply.\n        *args: Positional arguments to pass to the indicator function.\n        **kwargs: Keyword arguments to pass to the indicator function.\n\n    Returns:\n        pd.DataFrame: The DataFrame with the calculated indicator(s) added.\n    \"\"\"\n    if field in df.columns:\n        result_dfs = []\n        for group_value, group_df in df.groupby(field):\n            result_dfs.append(indicator_function(group_df.copy(), *args, **kwargs).assign(**{field: group_value}))\n        rv = pd.concat(result_dfs)\n        return rv.drop(field, axis=1)\n    else:\n        return indicator_function(df.copy(), *args, **kwargs)\n\n\n# Note: I am not completely happy with how this works; ideally, this would be merged with calculate_indicator_by\ndef apply_daily_function(context, weights, f, *args, **kwargs):\n    if(isinstance(weights, str)):\n        foo = context.groupby(\"date\")[weights].apply(lambda a: f(context, a, *args, **kwargs))\n    else:\n        foo = weights.groupby(by=context[\"date\"]).apply(lambda a: f(context, a, *args, **kwargs))\n    # Swap levels and drop the 'date' level\n    foo.index = foo.index.droplevel(\"date\")    \n    return foo.iloc[:, 0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T19:38:32.390075Z","iopub.execute_input":"2025-03-12T19:38:32.390410Z","iopub.status.idle":"2025-03-12T19:38:32.426873Z","shell.execute_reply.started":"2025-03-12T19:38:32.390382Z","shell.execute_reply":"2025-03-12T19:38:32.425908Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Functions to calculate basic technical indicators\n\n# SMA\ndef do_calculate_sma(df: pd.DataFrame, length: int) -> pd.DataFrame:\n    print(f\"calculate_sma(df, {length})\")\n    sma_values = df['close'].rolling(window=length).mean().values\n    return pd.DataFrame({f\"SMA({length})\": sma_values}, index=df.index)\n\n# RSI\ndef do_calculate_rsi(df: pd.DataFrame, length: int) -> pd.DataFrame:\n    length = int(length)\n    delta = df['close'].diff()\n    gains = delta.clip(lower=0)\n    losses = -delta.clip(upper=0)\n    avg_gains = gains.rolling(window=length).mean()\n    avg_losses = losses.rolling(window=length).mean()\n    rs = avg_gains / avg_losses.replace(0, float('inf'))\n    rsi = 100 - (100 / (1 + rs))\n    rsi_values = rsi.values\n    return pd.DataFrame({f\"RSI({length})\": rsi_values}, index=df.index)\n\n# MACD\ndef do_calculate_macd(df: pd.DataFrame, fast_length: int, slow_length: int, signal_length: int) -> pd.DataFrame:\n    ema_fast = df['close'].ewm(span=fast_length, adjust=False).mean()\n    ema_slow = df['close'].ewm(span=slow_length, adjust=False).mean()\n    macd = ema_fast - ema_slow\n    signal = macd.ewm(span=signal_length, adjust=False).mean()\n    histogram = macd - signal\n    return pd.DataFrame({f'MACD({fast_length},{slow_length},{signal_length})[\"macd\"]': macd.values, f'MACD({fast_length},{slow_length},{signal_length})[\"signal\"]': signal.values, f'MACD({fast_length},{slow_length},{signal_length})[\"histogram\"]': histogram.values}, index=df.index)\n\n# Bollinger Bands\ndef do_calculate_bollinger_bands(df: pd.DataFrame, length: int, std_dev: float) -> pd.DataFrame:\n    rolling_mean = df['close'].rolling(window=length).mean()\n    rolling_std = df['close'].rolling(window=length).std()\n    upper_band = rolling_mean + (rolling_std * std_dev)\n    lower_band = rolling_mean - (rolling_std * std_dev)\n    middle_values = rolling_mean.values\n    upper_values = upper_band.values\n    lower_values = lower_band.values\n    bb_df = pd.DataFrame({f'BB({length},{std_dev})[\"middle\"]': middle_values, f'BB({length},{std_dev})[\"upper\"]': upper_values, f'BB({length},{std_dev})[\"lower\"]': lower_values}, index=df.index)\n    return bb_df\n\n# Rolling VWAP\ndef do_calculate_rvwap(df: pd.DataFrame, length: int) -> pd.DataFrame:\n    typical_price = (df['high'] + df['low'] + df['close']) / 3\n    rolling_volume = df['volume'].rolling(length).sum()\n    typical_price_x_volume = df[\"volume\"] * typical_price\n    rolling_typical_price_x_volume = typical_price_x_volume.rolling(length).sum()\n    vwap = rolling_typical_price_x_volume / rolling_volume\n    return pd.DataFrame({f\"RVWAP({length})\": vwap.values}, index=df.index)\n\n# Average True Range\ndef do_calculate_atr(df, length):\n    \"\"\"Calculates Average True Range (ATR).\"\"\"\n    tr1 = df[\"high\"] - df[\"low\"]\n    tr2 = abs(df[\"high\"] - df[\"close\"].shift(1))\n    tr3 = abs(df[\"low\"] - df[\"close\"].shift(1))\n    true_range = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n    atr = true_range.rolling(window=length).mean()\n    return pd.DataFrame({f\"ATR({length})\": atr}, index=df.index)\n\n# ADX\ndef do_calculate_adx(df, length):\n    \"\"\"Calculates Average Directional Index (ADX) and Directional Movement Indicators.\"\"\"\n    high = df[\"high\"]\n    low = df[\"low\"]\n    close = df[\"close\"]\n\n    upmove = high - high.shift(1)\n    downmove = low.shift(1) - low\n    plus_dm = pd.Series(np.where((upmove > downmove) & (upmove > 0), upmove, 0))\n    minus_dm = pd.Series(np.where((downmove > upmove) & (downmove > 0), downmove, 0))\n\n    tr1 = high - low\n    tr2 = abs(high - close.shift(1))\n    tr3 = abs(df[\"low\"] - df[\"close\"].shift(1))\n    true_range = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n\n    # Calculate +DI and -DI\n    plus_di = 100 * (plus_dm.ewm(alpha=1 / length).mean() / true_range.ewm(alpha=1 / length).mean())\n    minus_di = 100 * (minus_dm.ewm(alpha=1 / length).mean() / true_range.ewm(alpha=1 / length).mean())\n\n    # Calculate DX\n    dx = 100 * np.abs(plus_di - minus_di) / (plus_di + minus_di).replace(0, np.inf)\n\n    # Calculate ADX\n    adx = dx.ewm(alpha=1 / length).mean().fillna(0)\n\n    return pd.DataFrame({f\"ADX({length}):adx\": adx, f\"ADX({length}):pdi\": plus_di, f\"ADX({length})mdi\": minus_di}, index=df.index)\n\n# Commodity Channel Index\ndef do_calculate_cci(df, length):\n    \"\"\"Calculates Commodity Channel Index (CCI).\"\"\"\n    typical_price = (df[\"high\"] + df[\"low\"] + df[\"close\"]) / 3\n    ma_typical_price = typical_price.rolling(window=length).mean()\n    mean_deviation = pd.Series(abs(typical_price - ma_typical_price)).rolling(window=length).mean()\n    cci = (typical_price - ma_typical_price) / (0.015 * mean_deviation)\n    return pd.DataFrame({f\"CCI({length})\": cci})\n\n# Chaikin Money Flow\ndef do_calculate_cmf(df, length):\n    \"\"\"Calculates Chaikin Money Flow (CMF).\"\"\"\n    money_flow = ((df[\"close\"] - df[\"low\"]) - (df[\"high\"] - df[\"close\"])) / (df[\"high\"] - df[\"low\"]) * df[\"volume\"]\n    money_flow_volume = money_flow.rolling(window=length).sum()\n    volume_sum = df[\"volume\"].rolling(window=length).sum()\n    cmf = money_flow_volume / volume_sum\n    return pd.DataFrame({f\"CMF({length})\": cmf}, index=df.index)\n\n# Aroon\ndef do_calculate_aroon(df, length):\n    \"\"\"Calculates Aroon Up and Aroon Down (incremental optimization).\"\"\"\n    high = df[\"high\"].values\n    low = df[\"low\"].values\n    aroon_up = np.zeros(len(df))\n    aroon_down = np.zeros(len(df))\n\n    if len(df) < length:\n        return pd.DataFrame({f\"AROON({length}):up\": aroon_up, f\"AROON({length}):down\": aroon_down}, index=df.index)\n\n    highest_index = 0\n    lowest_index = 0\n\n    for i in range(length, len(df)):\n        window_start = i - length\n\n        # Update highest index\n        if highest_index < window_start:  # If the previous highest is outside the window\n            highest_index = window_start\n            for j in range(window_start + 1, i):\n                if high[j] > high[highest_index]:\n                    highest_index = j\n        elif high[i - 1] >= high[highest_index]:\n            highest_index = i - 1\n\n        # Update lowest index\n        if lowest_index < window_start:  # If the previous lowest is outside the window\n            lowest_index = window_start\n            for j in range(window_start + 1, i):\n                if low[j] < low[lowest_index]:\n                    lowest_index = j\n        elif low[i - 1] <= low[lowest_index]:\n            lowest_index = i - 1\n\n        aroon_up[i] = (length - (i - 1 - highest_index)) * 100.0 / length\n        aroon_down[i] = (length - (i - 1 - lowest_index)) * 100.0 / length\n\n    return pd.DataFrame({f\"AROON({length}):up\": aroon_up, f\"AROON({length}):down\": aroon_down}, index=df.index)\n\n# MFI\ndef do_calculate_mfi(df, length):\n    \"\"\"Calculates Money Flow Index (MFI).\"\"\"\n    typical_price = (df[\"high\"] + df[\"low\"] + df[\"close\"]) / 3\n    money_flow = typical_price * df[\"volume\"]\n\n    positive_money_flow = money_flow[df[\"close\"] > df[\"close\"].shift(1)]\n    negative_money_flow = money_flow[df[\"close\"] <= df[\"close\"].shift(1)]\n\n    positive_money_flow = positive_money_flow.rolling(window=length).sum()\n    negative_money_flow = abs(negative_money_flow.rolling(window=length).sum())\n\n    money_ratio = positive_money_flow / negative_money_flow\n    mfi = 100 - (100 / (1 + money_ratio))\n    return pd.DataFrame({f\"MFI({length})\": mfi}, index=df.index)\n\n# Percent Rank\ndef do_calculate_pct_rank(df, length):\n    \"\"\"Calculates percentile rank using pandas only.\"\"\"\n    pct_rank = df['close'].rolling(window=length).apply(lambda x: (x < x[-1]).sum() / (len(x)-1) if len(x) > 1 else 0, raw=True)\n    return pd.DataFrame({f\"PCT({length})\": pct_rank}, index=df.index)\n\n# Price Range Percentage\ndef do_calculate_prp(df, length):\n    \"\"\"Calculates the Price Range Percentage.\"\"\"\n    high_max = df[\"high\"].rolling(window=length).max()\n    low_min = df[\"low\"].rolling(window=length).min()\n    range_width = high_max - low_min\n    price_percentage = (df[\"close\"] - low_min) / range_width * 100\n    return pd.DataFrame({f\"PRP({length})\": price_percentage}, index=df.index)\n\n# Log Return\ndef do_calculate_lret(df, length):\n    \"\"\"Calculates Log Return\"\"\"\n    v = (df[\"close\"] / df[\"close\"].shift(length)).apply(lambda a: np.log(a) if a != np.nan else np.nan)\n    return pd.DataFrame({f\"LRET({length})\": v}, index=df.index)\n\n# Shift\ndef do_calculate_shift(df, series=\"close\", n=1):\n    name = \"!unknown\"\n    if isinstance(series, str):\n        name = series\n        series = df[series]\n    elif isinstance(series, pd.DataFrame):\n        if(series.shape[1] != 1):\n            raise ValueError(f\"Shift() currently will operate on a single column only\")\n        name = series.columns[0]\n        series = series.iloc[:, 0]\n    elif isinstance(series, pd.Series):\n        name = series.name\n    return pd.DataFrame({f\"Shift({name},{n})\":series.shift(n)}, index=series.index)\n","metadata":{"_uuid":"b60780a9-1f5a-4510-9108-59c7456450e8","_cell_guid":"560302f4-41a4-460a-989f-3ec4dbd7bad7","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-12T19:38:32.427859Z","iopub.execute_input":"2025-03-12T19:38:32.428456Z","iopub.status.idle":"2025-03-12T19:38:32.543925Z","shell.execute_reply.started":"2025-03-12T19:38:32.428421Z","shell.execute_reply":"2025-03-12T19:38:32.542752Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Basic candlestick pattern detection\ndef do_calculate_hammer(df: pd.DataFrame) -> pd.Series:\n    \"\"\"Detects Hammer candlestick pattern.\"\"\"\n    body = df['close'] - df['open']\n    lower_wick = abs(df['low'] - min(df['open'], df['close']))\n    upper_wick = abs(df['high'] - max(df['open'], df['close']))\n    return (body < 0) & (lower_wick >= 2 * abs(body)) & (upper_wick <= abs(body) / 2)\n\ndef do_calculate_inverted_hammer(df: pd.DataFrame) -> pd.Series:\n    \"\"\"Detects Inverted Hammer candlestick pattern.\"\"\"\n    body = df['close'] - df['open']\n    lower_wick = abs(df['low'] - min(df['open'], df['close']))\n    upper_wick = abs(df['high'] - max(df['open'], df['close']))\n    return (body > 0) & (upper_wick >= 2 * body) & (lower_wick <= body / 2)\n\ndef do_calculate_hanging_man(df: pd.DataFrame) -> pd.Series:\n    \"\"\"Detects Hanging Man candlestick pattern.\"\"\"\n    body = df['close'] - df['open']\n    lower_wick = abs(df['low'] - min(df['open'], df['close']))\n    upper_wick = abs(df['high'] - max(df['open'], df['close']))\n    return (body < 0) & (lower_wick >= 2 * abs(body)) & (upper_wick <= abs(body) / 2) & (df['high'] > df['high'].shift(1))\n\ndef do_calculate_shooting_star(df: pd.DataFrame) -> pd.Series:\n    \"\"\"Detects Shooting Star candlestick pattern.\"\"\"\n    body = df['close'] - df['open']\n    lower_wick = abs(df['low'] - min(df['open'], df['close']))\n    upper_wick = abs(df['high'] - max(df['open'], df['close']))\n    return (body > 0) & (upper_wick >= 2 * body) & (lower_wick <= body / 2) & (df['low'] < df['low'].shift(1))\n\ndef do_calculate_engulfing_bullish(df: pd.DataFrame) -> pd.Series:\n    \"\"\"Detects Bullish Engulfing candlestick pattern.\"\"\"\n    prev_body_len = abs(df['close'].shift(1) - df['open'].shift(1))\n    current_body_len = abs(df['close'] - df['open'])\n    return (df['open'].shift(1) > df['close'].shift(1)) & (df['open'] < df['close'].shift(1)) & (df['close'] > df['open'].shift(1)) & (current_body_len > prev_body_len)\n\ndef do_calculate_engulfing_bearish(df: pd.DataFrame) -> pd.Series:\n    \"\"\"Detects Bearish Engulfing candlestick pattern.\"\"\"\n    prev_body_len = abs(df['close'].shift(1) - df['open'].shift(1))\n    current_body_len = abs(df['close'] - df['open'])\n    return (df['open'].shift(1) < df['close'].shift(1)) & (df['open'] > df['close'].shift(1)) & (df['close'] < df['open'].shift(1)) & (current_body_len > prev_body_len)\n\ndef do_calculate_doji(df: pd.DataFrame) -> pd.Series:\n    \"\"\"Detects Doji candlestick pattern.\"\"\"\n    body = abs(df['close'] - df['open'])\n    return body < 0.01 * (df['high'] - df['low']) # Adjust 0.01 for sensitivity\n\ndef do_calculate_morning_star(df: pd.DataFrame) -> pd.Series:\n    \"\"\"Detects Morning Star candlestick pattern (simplified).\"\"\"\n    # Requires more sophisticated logic for accurate detection. This is a simplified version.\n    return (df['close'].shift(2) < df['open'].shift(2)) & (df['close'].shift(1) < df['open'].shift(1)) & (df['close'] > df['open'])\ndef do_calculate_evening_star(df: pd.DataFrame) -> pd.Series:\n    \"\"\"Detects Evening Star candlestick pattern (simplified).\"\"\"\n    # Requires more sophisticated logic for accurate detection. This is a simplified version.\n    return (df['close'].shift(2) > df['open'].shift(2)) & (df['close'].shift(1) > df['open'].shift(1)) & (df['close'] < df['open'])\n\n\ndef do_calculate_three_white_soldiers(df: pd.DataFrame) -> pd.Series:\n    \"\"\"Detects Three White Soldiers candlestick pattern.\"\"\"\n    return (df['open'] > df['close'].shift(1)) & (df['close'] > df['open']) & (df['open'].shift(1) > df['close'].shift(2)) & (df['close'].shift(1) > df['open'].shift(2)) & (df['close'] > df['open'].shift(1))\n\n\ndef do_calculate_three_black_crows(df: pd.DataFrame) -> pd.Series:\n    \"\"\"Detects Three Black Crows candlestick pattern.\"\"\"\n    return (df['open'] < df['close'].shift(1)) & (df['close'] < df['open']) & (df['open'].shift(1) < df['close'].shift(2)) & (df['close'].shift(1) < df['open'].shift(2)) & (df['close'] < df['open'].shift(1))\n\n\ndef do_calculate_piercing_line(df: pd.DataFrame) -> pd.Series:\n    \"\"\"Detects Piercing Line candlestick pattern.\"\"\"\n    return (df['close'].shift(1) < df['open'].shift(1)) & (df['open'] < df['close'].shift(1)) & (df['close'] > df['open']) & (df['close'] > (df['open'].shift(1) + df['close'].shift(1)) / 2)\n\n\ndef do_calculate_dark_cloud_cover(df: pd.DataFrame) -> pd.Series:\n    \"\"\"Detects Dark Cloud Cover candlestick pattern.\"\"\"\n    return (df['close'].shift(1) > df['open'].shift(1)) & (df['open'] > df['close'].shift(1)) & (df['close'] < df['open']) & (df['close'] < (df['open'].shift(1) + df['close'].shift(1)) / 2)\n\n\ndef do_calculate_harami(df: pd.DataFrame) -> pd.Series:\n    \"\"\"Detects Harami candlestick pattern (both bullish and bearish).\"\"\"\n    return ((df['open'].shift(1) > df['close'].shift(1)) & (df['open'] < df['close'].shift(1)) & (df['close'] > df['open']) & (df['high'] < df['high'].shift(1)) ) | ( (df['open'].shift(1) < df['close'].shift(1)) & (df['open'] > df['close'].shift(1)) & (df['close'] < df['open']) & (df['low'] > df['low'].shift(1)) )\n\n\ndef do_calculate_bullish_abandoned_baby(df:pd.DataFrame) -> pd.Series:\n    \"\"\" Detects Bullish Abandoned Baby \"\"\"\n    return (df['close'].shift(1) < df['open'].shift(1)) & (df['high'].shift(1) > df['high']) & (df['low'].shift(1) < df['low']) & (df['open'] < df['close'].shift(1)) & (df['close'] > df['open'])\n\ndef do_calculate_bearish_abandoned_baby(df:pd.DataFrame) -> pd.Series:\n    \"\"\" Detects Bearish Abandoned Baby \"\"\"\n    return (df['close'].shift(1) > df['open'].shift(1)) & (df['high'].shift(1) > df['high']) & (df['low'].shift(1) < df['low']) & (df['open'] > df['close'].shift(1)) & (df['close'] < df['open'])\n\n\"\"\"\nImportant Considerations:\n\nSimplified Logic: Many candlestick patterns have nuanced definitions. The functions above provide a basic detection, and more robust implementations might require more complex logic and potentially incorporating additional criteria (e.g., body size relative to the entire candle range, specific relationships between shadows and bodies).\nParameterization: You could enhance these functions by adding parameters to control sensitivity (e.g., minimum body size, maximum wick length).\nData Quality: The accuracy of pattern detection relies heavily on clean and reliable OHLCV data. Outliers or errors in your data can lead to false positives or negatives.\nContext: Candlestick patterns are most meaningful when considered within a broader technical analysis context. Using these functions alone shouldn't be the sole basis for trading decisions.\nRemember to thoroughly test these functions with your data and refine them based on your specific requirements and trading strategy. You may need to adjust thresholds or add more conditions to achieve optimal performance.\n\"\"\"\n\ndef do_calculate_morning_doji_star(df: pd.DataFrame) -> pd.Series:\n    \"\"\"Detects Morning Doji Star pattern.\"\"\"\n    #Simplified version,  a more robust version would include checks on body sizes and wick lengths.\n    return (df['close'].shift(1) < df['open'].shift(1)) & (abs(df['close'] - df['open']) < 0.01 * (df['high'] - df['low'])) & (df['close'] > df['open'].shift(1))\n\n\ndef do_calculate_evening_doji_star(df: pd.DataFrame) -> pd.Series:\n    \"\"\"Detects Evening Doji Star pattern.\"\"\"\n    #Simplified version, a more robust version would include checks on body sizes and wick lengths.\n    return (df['close'].shift(1) > df['open'].shift(1)) & (abs(df['close'] - df['open']) < 0.01 * (df['high'] - df['low'])) & (df['close'] < df['open'].shift(1))\n\n\ndef do_calculate_spinning_top(df: pd.DataFrame) -> pd.Series:\n    \"\"\"Detects Spinning Top pattern (both bullish and bearish).\"\"\"\n    body = abs(df['close'] - df['open'])\n    total_range = df['high'] - df['low']\n    return body < 0.1 * total_range # Adjust 0.1 for sensitivity\n\n\ndef do_calculate_long_legged_doji(df: pd.DataFrame) -> pd.Series:\n    \"\"\"Detects Long Legged Doji pattern.\"\"\"\n    body = abs(df['close'] - df['open'])\n    upper_wick = df['high'] - max(df['open'], df['close'])\n    lower_wick = min(df['open'], df['close']) - df['low']\n    return (body < 0.1 * (upper_wick + lower_wick)) & (upper_wick > body) & (lower_wick > body) # Adjust 0.1 for sensitivity\n\n\ndef do_calculate_abandoned_baby(df: pd.DataFrame) -> pd.Series:\n    \"\"\"Detects Abandoned Baby pattern (both bullish and bearish). This is a simplified version.\"\"\"\n    #A more robust version would add checks on the size of the gaps and the relationship between the bodies and wicks.\n\n    gap_above = df['open'].shift(1) > df['close'].shift(1)\n    gap_below = df['open'] > df['close'].shift(1)\n    return (gap_above & gap_below & (df['close'] > df['open'])) | (gap_above & gap_below & (df['close'] < df['open']))\n\n\ndef do_calculate_bullish_kicking_by(df: pd.DataFrame) -> pd.Series:\n    \"\"\"Detects Bullish Kicking-By pattern (simplified).\"\"\"\n    return (df['open'].shift(1) > df['close'].shift(1)) & (df['open'] < df['close'].shift(1)) & (df['close'] > df['open']) & (df['close'] > df['high'].shift(1))\n\n\ndef do_calculate_bearish_kicking_by(df: pd.DataFrame) -> pd.Series:\n    \"\"\"Detects Bearish Kicking-By pattern (simplified).\"\"\"\n    return (df['open'].shift(1) < df['close'].shift(1)) & (df['open'] > df['close'].shift(1)) & (df['close'] < df['open']) & (df['close'] < df['low'].shift(1))\n\n\n\"\"\"\nImportant Notes:\n\nSimplification: These functions represent simplified versions of the patterns. Real-world detection often needs more sophisticated criteria (e.g., precise relationships between body and wick lengths, consideration of volume, context within a trend).\nThreshold Tuning: The numerical thresholds (like 0.1 or 0.01) are arbitrary. You'll likely need to fine-tune them based on your data and the desired sensitivity. Experiment to find optimal values.\nCompleteness: Candlestick patterns are complex, and many variations exist. These functions cover some common patterns, but not all.\nFalse Positives/Negatives: Be aware that even with refined criteria, some false positives and negatives are possible. Always validate the pattern identification visually and within the context of your overall trading strategy.\nRemember to carefully test these functions and adjust parameters to suit your needs before using them in any trading system. Always use caution and consider other factors when making investment decisions.\n\"\"\"\n\n\ndef do_calculate_engulfing_pattern(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Detects both bullish and bearish engulfing patterns.  A more robust version would check for complete engulfment.\n    \"\"\"\n    prev_body_size = abs(df['close'].shift(1) - df['open'].shift(1))\n    current_body_size = abs(df['close'] - df['open'])\n    bullish = (df['open'].shift(1) > df['close'].shift(1)) & (df['open'] < df['close'].shift(1)) & (df['close'] > df['open'].shift(1)) & (current_body_size > prev_body_size)\n    bearish = (df['open'].shift(1) < df['close'].shift(1)) & (df['open'] > df['close'].shift(1)) & (df['close'] < df['open'].shift(1)) & (current_body_size > prev_body_size)\n    return bullish | bearish\n\n\ndef do_calculate_inside_day(df: pd.DataFrame) -> pd.Series:\n    \"\"\"Detects an Inside Day pattern.\"\"\"\n    return (df['high'] < df['high'].shift(1)) & (df['low'] > df['low'].shift(1))\n\n\ndef do_calculate_outside_day(df: pd.DataFrame) -> pd.Series:\n    \"\"\"Detects an Outside Day pattern.\"\"\"\n    return (df['high'] > df['high'].shift(1)) & (df['low'] < df['low'].shift(1))\n\n\ndef do_calculate_three_inside_up(df: pd.DataFrame) -> pd.Series:\n    \"\"\"Detects a Three Inside Up pattern (simplified).\"\"\"\n    return (df['high'] < df['high'].shift(1)) & (df['low'] > df['low'].shift(1)) & (df['high'].shift(1) < df['high'].shift(2)) & (df['low'].shift(1) > df['low'].shift(2)) & (df['close'] > df['open'])\n\n\ndef do_calculate_three_inside_down(df: pd.DataFrame) -> pd.Series:\n    \"\"\"Detects a Three Inside Down pattern (simplified).\"\"\"\n    return (df['high'] < df['high'].shift(1)) & (df['low'] > df['low'].shift(1)) & (df['high'].shift(1) < df['high'].shift(2)) & (df['low'].shift(1) > df['low'].shift(2)) & (df['close'] < df['open'])\n\n\ndef do_calculate_two_crows(df: pd.DataFrame) -> pd.Series:\n    \"\"\"Detects a Two Crows pattern (simplified).\"\"\"\n    return (df['open'] > df['close'].shift(1)) & (df['close'] < df['open']) & (df['open'].shift(1) > df['close'].shift(2)) & (df['close'].shift(1) < df['open'].shift(2)) & (df['open'] < df['open'].shift(1)) & (df['close'] < df['close'].shift(1))\n\n\ndef do_calculate_on_neckline(df: pd.DataFrame) -> pd.Series:\n  \"\"\"Detects a On-Neckline pattern (simplified, requires additional inputs for neckline calculation).\"\"\"\n  #This function needs additional logic to define the neckline.  This is a placeholder.\n  #You would need to add a function or method to determine the neckline price level.\n  neckline = 150 #Replace with actual neckline calculation.\n  return df['close'] > neckline\n\n\ndef do_calculate_breakaway(df: pd.DataFrame) -> pd.Series:\n    \"\"\"Detects a Breakaway pattern (simplified). Requires additional logic for range breakout calculation.\"\"\"\n    # This is a placeholder; a real implementation would need to dynamically calculate the breakout range.\n    high = df['high'].max()\n    low = df['low'].min()\n    return df['close'] > high  # Or df['close'] < low, depending on the direction of the breakout\n\n\n\"\"\"\nCrucial Considerations:\n\nPattern Complexity: Many of these patterns (especially those involving multiple candles) require more intricate logic than what's shown here for truly reliable detection. The simplified versions presented above might produce false positives or negatives.\nContextual Analysis: Candlestick patterns gain significance when considered within the broader market context (trends, volume, support/resistance levels). Don't rely solely on pattern identification for trading decisions.\nParameterization: Consider adding parameters to tune the sensitivity of the detection (e.g., minimum body size, percentage changes, etc.).\nVisual Verification: Always visually inspect the charts to confirm the patterns detected by your functions. Automated detection alone isn't enough for robust trading strategies.\nThese enhanced functions provide a more comprehensive, though still simplified, approach to candlestick pattern recognition. Remember to thoroughly test and validate them before using them in any trading system. Always prioritize risk management and diversify your investment strategies.\n\"\"\"\n\ndef do_calculate_bullish_engulfing(df: pd.DataFrame) -> pd.Series:\n    \"\"\"Detects a bullish engulfing pattern with more robust criteria.\"\"\"\n    prev_close = df['close'].shift(1)\n    prev_open = df['open'].shift(1)\n    current_close = df['close']\n    current_open = df['open']\n\n    #More robust checks:\n    is_bullish_engulfing = (prev_close < prev_open) & (current_open < prev_close) & (current_close > prev_open) & (current_close > current_open)\n\n    return is_bullish_engulfing\n\n\ndef do_calculate_bearish_engulfing(df: pd.DataFrame) -> pd.Series:\n    \"\"\"Detects a bearish engulfing pattern with more robust criteria.\"\"\"\n    prev_close = df['close'].shift(1)\n    prev_open = df['open'].shift(1)\n    current_close = df['close']\n    current_open = df['open']\n\n    #More robust checks:\n    is_bearish_engulfing = (prev_close > prev_open) & (current_open > prev_close) & (current_close < prev_open) & (current_close < current_open)\n\n    return is_bearish_engulfing\n\n\ndef do_calculate_morning_star(df: pd.DataFrame) -> pd.Series:\n    \"\"\"Detects a morning star pattern (more robust version).\"\"\"\n    # Needs more sophisticated logic for reliable detection. This is still a simplified version.\n    prev2_close = df['close'].shift(2)\n    prev2_open = df['open'].shift(2)\n    prev_close = df['close'].shift(1)\n    prev_open = df['open'].shift(1)\n    current_close = df['close']\n    current_open = df['open']\n\n    is_morning_star = (prev2_close < prev2_open) & (prev_close < prev_open) & (current_close > current_open) & (current_open < prev_close)\n\n    return is_morning_star\n\n\ndef do_calculate_evening_star(df: pd.DataFrame) -> pd.Series:\n    \"\"\"Detects an evening star pattern (more robust version).\"\"\"\n    # Needs more sophisticated logic for reliable detection. This is still a simplified version.\n    prev2_close = df['close'].shift(2)\n    prev2_open = df['open'].shift(2)\n    prev_close = df['close'].shift(1)\n    prev_open = df['open'].shift(1)\n    current_close = df['close']\n    current_open = df['open']\n\n    is_evening_star = (prev2_close > prev2_open) & (prev_close > prev_open) & (current_close < current_open) & (current_open > prev_close)\n\n    return is_evening_star\n\n\ndef do_calculate_piercing_line(df: pd.DataFrame) -> pd.Series:\n    \"\"\"Detects a piercing line pattern (more robust version).\"\"\"\n    prev_close = df['close'].shift(1)\n    prev_open = df['open'].shift(1)\n    current_close = df['close']\n    current_open = df['open']\n    midpoint = (prev_open + prev_close) / 2\n\n    is_piercing_line = (prev_close < prev_open) & (current_open < prev_close) & (current_close > midpoint) & (current_close > current_open)\n\n    return is_piercing_line\n\n\n\ndef do_calculate_dark_cloud_cover(df: pd.DataFrame) -> pd.Series:\n    \"\"\"Detects a dark cloud cover pattern (more robust version).\"\"\"\n    prev_close = df['close'].shift(1)\n    prev_open = df['open'].shift(1)\n    current_close = df['close']\n    current_open = df['open']\n    midpoint = (prev_open + prev_close) / 2\n\n    is_dark_cloud_cover = (prev_close > prev_open) & (current_open > prev_close) & (current_close < midpoint) & (current_close < current_open)\n\n    return is_dark_cloud_cover\n\n\"\"\"\nEnhancements:\n\nMore Precise Conditions: These functions incorporate stricter criteria to reduce false positives. For example, the engulfing patterns now explicitly check if the current candle's body completely engulfs the previous candle's body (though this could be further refined). The Morning/Evening Star and Piercing/Dark Cloud Cover patterns now include midpoint checks to ensure a stronger signal.\nClarity and Readability: The code is restructured for improved readability, using more descriptive variable names.\nImportant Reminder: Even with these improvements, candlestick pattern recognition is not foolproof. Always cross-reference your results with other technical indicators and fundamental analysis before making any investment decisions. These functions should be part of a comprehensive trading strategy, not the sole basis for your trades.\n\"\"\"\n\ndef do_calculate_hammer(df: pd.DataFrame, hammer_body_factor: float = 0.2, hammer_wick_factor: float = 2.0) -> pd.Series:\n    \"\"\"\n    Detects Hammer candlestick pattern with customizable parameters.\n\n    Args:\n        df: DataFrame with OHLC data.\n        hammer_body_factor: Factor determining the maximum body size relative to the lower wick.\n        hammer_wick_factor: Factor determining the minimum lower wick length relative to the body size.\n\n    Returns:\n        pandas.Series: Boolean Series indicating hammer patterns.\n    \"\"\"\n    body = abs(df['close'] - df['open'])\n    lower_wick = df['close'] - df['low'] if df['close'] < df['open'] else df['open'] - df['low']\n    upper_wick = df['high'] - max(df['open'], df['close'])\n\n    # Check conditions for the hammer pattern\n    is_hammer = (body > 0) & (lower_wick >= hammer_wick_factor * body) & (upper_wick <= hammer_body_factor * body) & (df['close'] > df['open'])\n\n\n    return is_hammer\n\ndef do_calculate_inverted_hammer(df: pd.DataFrame, inverted_hammer_body_factor: float = 0.2, inverted_hammer_wick_factor: float = 2.0) -> pd.Series:\n    \"\"\"\n    Detects Inverted Hammer candlestick pattern with customizable parameters.\n\n    Args:\n        df: DataFrame with OHLC data.\n        inverted_hammer_body_factor: Factor determining the maximum body size relative to the upper wick.\n        inverted_hammer_wick_factor: Factor determining the minimum upper wick length relative to the body size.\n\n    Returns:\n        pandas.Series: Boolean Series indicating inverted hammer patterns.\n    \"\"\"\n    body = abs(df['close'] - df['open'])\n    lower_wick = min(df['open'],df['close']) - df['low']\n    upper_wick = df['high'] - min(df['open'], df['close'])\n\n    # Check conditions for the inverted hammer pattern\n    is_inverted_hammer = (body > 0) & (upper_wick >= inverted_hammer_wick_factor * body) & (lower_wick <= inverted_hammer_body_factor * body) & (df['close'] < df['open'])\n\n    return is_inverted_hammer\n\n\n\ndef do_calculate_three_line_strike(df: pd.DataFrame, gap_threshold: float = 0.01) -> pd.Series:\n    \"\"\"\n    Detects Three Line Strike pattern (bullish).  Requires significant upward gaps.\n\n    Args:\n        df: DataFrame with OHLC data.\n        gap_threshold: Minimum percentage gap between consecutive candles.\n\n    Returns:\n        pandas.Series: Boolean Series indicating Three Line Strike patterns.\n    \"\"\"\n    \n    #Check for three consecutive days with significant upward gaps\n    is_three_line_strike = (df['open'] > df['close'].shift(1) * (1 + gap_threshold)) & \\\n                           (df['open'].shift(1) > df['close'].shift(2) * (1 + gap_threshold)) & \\\n                           (df['open'].shift(2) > df['close'].shift(3) * (1 + gap_threshold)) & \\\n                           (df['close'] > df['open']) & (df['close'].shift(1) > df['open'].shift(1)) & (df['close'].shift(2) > df['open'].shift(2))\n\n    return is_three_line_strike\n\n\ndef do_calculate_three_black_crows(df: pd.DataFrame, body_threshold: float = 0.2) -> pd.Series:\n    \"\"\"\n    Detects Three Black Crows pattern (bearish). Each candle should have significant body.\n\n    Args:\n        df: DataFrame with OHLC data.\n        body_threshold: Minimum body size as a fraction of the candle range\n\n    Returns:\n        pandas.Series: Boolean Series indicating Three Black Crows patterns\n    \"\"\"\n\n    #Check for three consecutive bearish candles with significant bodies.\n    is_three_black_crows = (df['close'] < df['open']) & (df['close'].shift(1) < df['open'].shift(1)) & (df['close'].shift(2) < df['open'].shift(2)) & \\\n                           (abs(df['close'] - df['open']) > body_threshold * (df['high'] - df['low'])) & \\\n                           (abs(df['close'].shift(1) - df['open'].shift(1)) > body_threshold * (df['high'].shift(1) - df['low'].shift(1))) & \\\n                           (abs(df['close'].shift(2) - df['open'].shift(2)) > body_threshold * (df['high'].shift(2) - df['low'].shift(2)))\n\n    return is_three_black_crows\n\n\"\"\"\nImportant Improvements:\n\nParameterization: The functions now accept parameters to adjust sensitivity (e.g., hammer_body_factor, gap_threshold). This allows you to fine-tune the pattern recognition to your specific needs and data characteristics.\nMore Robust Logic: The pattern detection logic has been made more robust by including additional checks and conditions, making the pattern identification more reliable.\nClearer Variable Names: Variable names have been made more descriptive for enhanced readability and maintainability.\nRemember to carefully test these functions with your data and adjust the parameters to achieve optimal results. Visual inspection of the charts remains crucial for confirming the patterns identified by the functions. Do not rely solely on automated pattern recognition for making trading decisions.\n\"\"\"\n\ndef do_calculate_gravestone_doji(df: pd.DataFrame, upper_wick_threshold: float = 0.7) -> pd.Series:\n    \"\"\"\n    Detects Gravestone Doji pattern.\n\n    Args:\n        df: DataFrame with OHLC data.\n        upper_wick_threshold: Minimum ratio of upper wick length to total candle range.\n\n    Returns:\n        pandas.Series: Boolean Series indicating Gravestone Doji patterns.\n    \"\"\"\n    body = abs(df['close'] - df['open'])\n    total_range = df['high'] - df['low']\n    upper_wick = df['high'] - max(df['open'], df['close'])\n\n    is_gravestone_doji = (body < 0.1 * total_range) & (upper_wick > upper_wick_threshold * total_range)\n\n    return is_gravestone_doji\n\n\ndef do_calculate_dragonfly_doji(df: pd.DataFrame, lower_wick_threshold: float = 0.7) -> pd.Series:\n    \"\"\"\n    Detects Dragonfly Doji pattern.\n\n    Args:\n        df: DataFrame with OHLC data.\n        lower_wick_threshold: Minimum ratio of lower wick length to total candle range.\n\n    Returns:\n        pandas.Series: Boolean Series indicating Dragonfly Doji patterns.\n    \"\"\"\n    body = abs(df['close'] - df['open'])\n    total_range = df['high'] - df['low']\n    lower_wick = min(df['open'], df['close']) - df['low']\n\n    is_dragonfly_doji = (body < 0.1 * total_range) & (lower_wick > lower_wick_threshold * total_range)\n\n    return is_dragonfly_doji\n\n\n\ndef do_calculate_bullish_harami(df: pd.DataFrame, body_ratio_threshold:float = 0.5) -> pd.Series:\n    \"\"\"\n    Detects Bullish Harami pattern.\n\n    Args:\n        df: DataFrame with OHLC data.\n        body_ratio_threshold: Minimum ratio of the second candle's body size to the first candle's body size.\n\n    Returns:\n        pandas.Series: Boolean Series indicating Bullish Harami patterns.\n    \"\"\"\n    prev_body = abs(df['close'].shift(1) - df['open'].shift(1))\n    current_body = abs(df['close'] - df['open'])\n    \n    is_bullish_harami = (df['open'].shift(1) > df['close'].shift(1)) & (df['open'] < df['close'].shift(1)) & (df['close'] > df['open']) & (current_body < body_ratio_threshold * prev_body)\n\n    return is_bullish_harami\n\n\ndef do_calculate_bearish_harami(df: pd.DataFrame, body_ratio_threshold: float = 0.5) -> pd.Series:\n    \"\"\"\n    Detects Bearish Harami pattern.\n\n    Args:\n        df: DataFrame with OHLC data.\n        body_ratio_threshold: Minimum ratio of the second candle's body size to the first candle's body size.\n\n    Returns:\n        pandas.Series: Boolean Series indicating Bearish Harami patterns.\n    \"\"\"\n    prev_body = abs(df['close'].shift(1) - df['open'].shift(1))\n    current_body = abs(df['close'] - df['open'])\n\n    is_bearish_harami = (df['open'].shift(1) < df['close'].shift(1)) & (df['open'] > df['close'].shift(1)) & (df['close'] < df['open']) & (current_body < body_ratio_threshold * prev_body)\n\n    return is_bearish_harami\n\n\"\"\"\nKey Improvements:\n\nParameterization: The functions now include parameters to control the sensitivity of the pattern detection (e.g., upper_wick_threshold, body_ratio_threshold). This allows for customization based on your specific needs and data characteristics.\nClearer Logic: The code is structured for better readability and maintainability.\nMore Robust Checks: The conditions for pattern detection are more refined, reducing the likelihood of false positives.\nRemember to always visually inspect the charts to confirm the patterns detected by these functions and use caution in interpreting the results. These functions provide an automated method, but should be used within a wider context of technical analysis. Do not use them solely as the basis of your trading decisions.\n\"\"\"\n\ndef do_calculate_long_legged_doji(df: pd.DataFrame, wick_body_ratio: float = 2.0) -> pd.Series:\n    \"\"\"\n    Detects Long Legged Doji pattern.\n\n    Args:\n        df: DataFrame with OHLC data.\n        wick_body_ratio: Minimum ratio of the sum of upper and lower wicks to the body size.\n\n    Returns:\n        pandas.Series: Boolean Series indicating Long Legged Doji patterns.\n    \"\"\"\n    body = abs(df['close'] - df['open'])\n    upper_wick = df['high'] - max(df['open'], df['close'])\n    lower_wick = min(df['open'], df['close']) - df['low']\n\n    is_long_legged_doji = (body > 0) & ((upper_wick + lower_wick) >= wick_body_ratio * body)\n\n    return is_long_legged_doji\n\n\ndef do_calculate_spinning_top(df: pd.DataFrame, body_range_ratio: float = 0.1) -> pd.Series:\n    \"\"\"\n    Detects Spinning Top pattern.\n\n    Args:\n        df: DataFrame with OHLC data.\n        body_range_ratio: Maximum ratio of body size to the total candle range (high - low).\n\n    Returns:\n        pandas.Series: Boolean Series indicating Spinning Top patterns.\n    \"\"\"\n    body = abs(df['close'] - df['open'])\n    total_range = df['high'] - df['low']\n\n    is_spinning_top = (body > 0) & (body <= body_range_ratio * total_range)\n\n    return is_spinning_top\n\n\ndef do_calculate_abandoned_baby(df: pd.DataFrame, gap_threshold: float = 0.01) -> pd.Series:\n    \"\"\"\n    Detects Abandoned Baby pattern (both bullish and bearish). This is a simplified version, gap_threshold needs to be tuned carefully.\n\n    Args:\n        df: DataFrame with OHLC data.\n        gap_threshold: Minimum gap (as a percentage of the previous candle's range) required between candles.\n\n    Returns:\n        pandas.Series: Boolean Series indicating Abandoned Baby patterns (True for both bullish and bearish).\n    \"\"\"\n    prev_high = df['high'].shift(1)\n    prev_low = df['low'].shift(1)\n    prev_range = prev_high - prev_low\n    \n    bullish = (df['open'] < df['close'].shift(1)) & (df['close'] > df['open']) & (df['low'] > prev_high) & (df['high'] < prev_low + prev_range * (1 + gap_threshold))\n    bearish = (df['open'] > df['close'].shift(1)) & (df['close'] < df['open']) & (df['high'] < prev_low) & (df['low'] > prev_high - prev_range * (1 + gap_threshold))\n\n    return bullish | bearish\n\n\ndef do_calculate_bullish_kicking_by(df: pd.DataFrame, gap_threshold: float = 0.02) -> pd.Series:\n  \"\"\"\n  Detects Bullish Kicking-By pattern. This is a simplified version.\n  \"\"\"\n  prev_close = df['close'].shift(1)\n  current_open = df['open']\n  current_close = df['close']\n  \n  is_bullish_kicking_by = (current_open < prev_close) & (current_close > prev_close) & (current_close > current_open)\n\n  return is_bullish_kicking_by\n\n\ndef do_calculate_bearish_kicking_by(df: pd.DataFrame, gap_threshold: float = 0.02) -> pd.Series:\n  \"\"\"\n  Detects Bearish Kicking-By pattern. This is a simplified version.\n  \"\"\"\n  prev_close = df['close'].shift(1)\n  current_open = df['open']\n  current_close = df['close']\n  \n  is_bearish_kicking_by = (current_open > prev_close) & (current_close < prev_close) & (current_close < current_open)\n\n  return is_bearish_kicking_by\n\n\n\"\"\"\nEnhancements:\n\nMore Parameters: Added parameters for better tunability and control over the pattern detection sensitivity.\nImproved Logic: Refined the logic for certain patterns (e.g., abandoned_baby) to be more precise. However, even these improved versions are simplifications of complex patterns.\nReadability: Improved variable names and code structuring for better clarity.\nRemember to carefully evaluate and test these functions with your data. Adjust parameters as needed to fit your strategy and risk tolerance. Always visually inspect charts to confirm pattern identification and use these functions as one component of a more comprehensive technical analysis approach, not the sole determinant of trading actions.\n\"\"\"\n\ndef do_calculate_above_the_stomach(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Detects \"Above the Stomach\" pattern (requires definition and parameters).  This is a placeholder.\n    \"\"\"\n    # Needs a proper definition and parameters to be implemented.\n    return pd.Series(False, index=df.index)\n\n\ndef do_calculate_advance_block(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Detects \"Advance Block\" pattern (requires definition and parameters). This is a placeholder.\n    \"\"\"\n    # Needs a proper definition and parameters to be implemented.\n    return pd.Series(False, index=df.index)\n\n\n\ndef do_calculate_below_the_stomach(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Detects \"Below the Stomach\" pattern (requires definition and parameters). This is a placeholder.\n    \"\"\"\n    # Needs a proper definition and parameters to be implemented.\n    return pd.Series(False, index=df.index)\n\n\n\ndef do_calculate_concealing_baby_swallow(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Detects Concealing Baby Swallow pattern (requires definition and parameters). This is a placeholder.\n    \"\"\"\n    # Needs a proper definition and parameters to be implemented.\n    return pd.Series(False, index=df.index)\n\n\n\ndef do_calculate_deliberation(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Detects Deliberation pattern (requires definition and parameters). This is a placeholder.\n    \"\"\"\n    # Needs a proper definition and parameters to be implemented.\n    return pd.Series(False, index=df.index)\n\n\n\ndef do_calculate_downside_gap_three_methods(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Detects Downside Gap Three Methods pattern (requires definition and parameters). This is a placeholder.\n    \"\"\"\n    # Needs a proper definition and parameters to be implemented.\n    return pd.Series(False, index=df.index)\n\n\n\ndef do_calculate_downside_tasuki_gap(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Detects Downside Tasuki Gap pattern (requires definition and parameters). This is a placeholder.\n    \"\"\"\n    # Needs a proper definition and parameters to be implemented.\n    return pd.Series(False, index=df.index)\n\n\n\ndef do_calculate_event_patterns(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Detects Event Patterns (requires definition and parameters). This is a placeholder.\n    \"\"\"\n    # Needs a proper definition and parameters to be implemented.  This would likely involve external data.\n    return pd.Series(False, index=df.index)\n\n\ndef do_calculate_falling_3_methods(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Detects Falling 3 Methods pattern (requires definition and parameters). This is a placeholder.\n    \"\"\"\n    # Needs a proper definition and parameters to be implemented.\n    return pd.Series(False, index=df.index)\n\n\n\ndef do_calculate_falling_window(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Detects Falling Window pattern (requires definition and parameters). This is a placeholder.\n    \"\"\"\n    # Needs a proper definition and parameters to be implemented.\n    return pd.Series(False, index=df.index)\n\n\ndef do_calculate_hikkake(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Detects Hikkake pattern (requires definition and parameters). This is a placeholder.  This needs a robust definition for both bullish and bearish.\n    \"\"\"\n    # Needs a proper definition and parameters to be implemented.\n    return pd.Series(False, index=df.index)\n\n\ndef do_calculate_homing_pigeon(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Detects Homing Pigeon pattern (requires definition and parameters). This is a placeholder.\n    \"\"\"\n    # Needs a proper definition and parameters to be implemented.\n    return pd.Series(False, index=df.index)\n\n\n\ndef do_calculate_identical_three_crows(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Detects Identical Three Crows pattern (requires definition and parameters). This is a placeholder.\n    \"\"\"\n    # Needs a proper definition and parameters to be implemented.\n    return pd.Series(False, index=df.index)\n\n\n\ndef do_calculate_in_neck(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Detects In Neck pattern (requires definition and parameters). This is a placeholder.\n    \"\"\"\n    # Needs a proper definition and parameters to be implemented.\n    return pd.Series(False, index=df.index)\n\n\n\ndef do_calculate_ladder_bottom(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Detects Ladder Bottom pattern (requires definition and parameters). This is a placeholder.\n    \"\"\"\n    # Needs a proper definition and parameters to be implemented.\n    return pd.Series(False, index=df.index)\n\n\ndef do_calculate_last_engulfing_bottom(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Detects Last Engulfing Bottom pattern (requires definition and parameters). This is a placeholder.\n    \"\"\"\n    # Needs a proper definition and parameters to be implemented.\n    return pd.Series(False, index=df.index)\n\n\ndef do_calculate_last_engulfing_top(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Detects Last Engulfing Top pattern (requires definition and parameters). This is a placeholder.\n    \"\"\"\n    # Needs a proper definition and parameters to be implemented.\n    return pd.Series(False, index=df.index)\n\n\ndef do_calculate_matching_low(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Detects Matching Low pattern (requires definition and parameters). This is a placeholder.\n    \"\"\"\n    # Needs a proper definition and parameters to be implemented.\n    return pd.Series(False, index=df.index)\n\n\ndef do_calculate_mat_hold(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Detects Mat Hold pattern (requires definition and parameters). This is a placeholder.\n    \"\"\"\n    # Needs a proper definition and parameters to be implemented.\n    return pd.Series(False, index=df.index)\n\n\ndef do_calculate_on_neck(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Detects On Neck pattern (requires definition and parameters). This is a placeholder.\n    \"\"\"\n    # Needs a proper definition and parameters to be implemented.\n    return pd.Series(False, index=df.index)\n\n\ndef do_calculate_rickshaw_man(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Detects Rickshaw Man pattern (requires definition and parameters). This is a placeholder.\n    \"\"\"\n    # Needs a proper definition and parameters to be implemented.\n    return pd.Series(False, index=df.index)\n\n\ndef do_calculate_rising_3_methods(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Detects Rising 3 Methods pattern (requires definition and parameters). This is a placeholder.\n    \"\"\"\n    # Needs a proper definition and parameters to be implemented.\n    return pd.Series(False, index=df.index)\n\n\ndef do_calculate_rising_window(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Detects Rising Window pattern (requires definition and parameters). This is a placeholder.\n    \"\"\"\n    # Needs a proper definition and parameters to be implemented.\n    return pd.Series(False, index=df.index)\n\n\ndef do_calculate_stick_sandwich(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Detects Stick Sandwich pattern (requires definition and parameters). This is a placeholder.\n    \"\"\"\n    # Needs a proper definition and parameters to be implemented.\n    return pd.Series(False, index=df.index)\n\n\ndef do_calculate_takuri_line(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Detects Takuri Line pattern (requires definition and parameters). This is a placeholder.\n    \"\"\"\n    # Needs a proper definition and parameters to be implemented.\n    return pd.Series(False, index=df.index)\n\n\ndef do_calculate_three_outside_down(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Detects Three Outside Down pattern (requires definition and parameters). This is a placeholder.\n    \"\"\"\n    # Needs a proper definition and parameters to be implemented.\n    return pd.Series(False, index=df.index)\n\n\ndef do_calculate_three_outside_up(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Detects Three Outside Up pattern (requires definition and parameters). This is a placeholder.\n    \"\"\"\n    # Needs a proper definition and parameters to be implemented.\n    return pd.Series(False, index=df.index)\n\n\ndef do_calculate_three_stars_in_the_south(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Detects Three Stars in the South pattern (requires definition and parameters). This is a placeholder.\n    \"\"\"\n    # Needs a proper definition and parameters to be implemented.\n    return pd.Series(False, index=df.index)\n\n\ndef do_calculate_thrusting(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Detects Thrusting pattern (requires definition and parameters). This is a placeholder.\n    \"\"\"\n    # Needs a proper definition and parameters to be implemented.\n    return pd.Series(False, index=df.index)\n\n\ndef do_calculate_tweezers_bottom(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Detects Tweezers Bottom pattern (requires definition and parameters). This is a placeholder.\n    \"\"\"\n    # Needs a proper definition and parameters to be implemented.\n    return pd.Series(False, index=df.index)\n\n\ndef do_calculate_tweezers_top(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Detects Tweezers Top pattern (requires definition and parameters). This is a placeholder.\n    \"\"\"\n    # Needs a proper definition and parameters to be implemented.\n    return pd.Series(False, index=df.index)\n\n\ndef do_calculate_two_black_gapping(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Detects Two Black Gapping pattern (requires definition and parameters). This is a placeholder.\n    \"\"\"\n    # Needs a proper definition and parameters to be implemented.\n    return pd.Series(False, index=df.index)\n\n\ndef do_calculate_upside_gap_three_methods(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Detects Upside Gap Three Methods pattern (requires definition and parameters). This is a placeholder.\n    \"\"\"\n    # Needs a proper definition and parameters to be implemented.\n    return pd.Series(False, index=df.index)\n\n\ndef do_calculate_upside_gap_two_crows(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Detects Upside Gap Two Crows pattern (requires definition and parameters). This is a placeholder.\n    \"\"\"\n    # Needs a proper definition and parameters to be implemented.\n    return pd.Series(False, index=df.index)\n\n\ndef do_calculate_upside_tasuki_gap(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Detects Upside Tasuki Gap pattern (requires definition and parameters). This is a placeholder.\n    \"\"\"\n    # Needs a proper definition and parameters to be implemented.\n    return pd.Series(False, index=df.index)\n\n\ndef do_calculate_unique_three_river_bottom(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Detects Unique Three River Bottom pattern (requires definition and parameters). This is a placeholder.\n    \"\"\"\n    # Needs a proper definition and parameters to be implemented.\n    return pd.Series(False, index=df.index)\n\n\n\n\"\"\"\nExplanation:\n\nMany of the candlestick patterns listed require more complex logic and often rely on subjective interpretation. The placeholders above highlight this. To create functional implementations, you would need to research the precise definition of each pattern and then translate that definition into robust Python code that accurately identifies the patterns within your OHLCV data. This would likely involve many additional parameters to control sensitivity and handle variations in the pattern formations. Furthermore, some patterns may require context beyond a single candle or two and thus need to incorporate analysis of prior candle formations.\n\"\"\"\n\ndef do_calculate_bearish_three_line_strike(df: pd.DataFrame, gap_threshold: float = 0.02) -> pd.Series:\n    \"\"\"\n    Detects Bearish Three Line Strike pattern.\n\n    Args:\n        df: DataFrame with OHLC data.\n        gap_threshold: Minimum percentage gap between consecutive open and previous close.\n\n    Returns:\n        pandas.Series: Boolean Series indicating Bearish Three Line Strike patterns.\n    \"\"\"\n    is_bearish_three_line_strike = (df['open'] < df['close'].shift(1) * (1 - gap_threshold)) & \\\n                                   (df['open'].shift(1) < df['close'].shift(2) * (1 - gap_threshold)) & \\\n                                   (df['open'].shift(2) < df['close'].shift(3) * (1 - gap_threshold)) & \\\n                                   (df['close'] < df['open']) & (df['close'].shift(1) < df['open'].shift(1)) & (df['close'].shift(2) < df['open'].shift(2))\n\n    return is_bearish_three_line_strike\n\n\ndef do_calculate_bullish_three_line_strike(df: pd.DataFrame, gap_threshold: float = 0.02) -> pd.Series:\n    \"\"\"\n    Detects Bullish Three Line Strike pattern.\n\n    Args:\n        df: DataFrame with OHLC data.\n        gap_threshold: Minimum percentage gap between consecutive open and previous close.\n\n    Returns:\n        pandas.Series: Boolean Series indicating Bullish Three Line Strike patterns.\n    \"\"\"\n    is_bullish_three_line_strike = (df['open'] > df['close'].shift(1) * (1 + gap_threshold)) & \\\n                                   (df['open'].shift(1) > df['close'].shift(2) * (1 + gap_threshold)) & \\\n                                   (df['open'].shift(2) > df['close'].shift(3) * (1 + gap_threshold)) & \\\n                                   (df['close'] > df['open']) & (df['close'].shift(1) > df['open'].shift(1)) & (df['close'].shift(2) > df['open'].shift(2))\n\n    return is_bullish_three_line_strike\n\n\ndef do_calculate_three_black_crows(df: pd.DataFrame, body_threshold: float = 0.2) -> pd.Series:\n    \"\"\"\n    Detects Three Black Crows pattern.\n\n    Args:\n        df: DataFrame with OHLC data.\n        body_threshold: Minimum ratio of body size to candle range for each of the three candles.\n\n    Returns:\n        pandas.Series: Boolean Series indicating Three Black Crows patterns.\n    \"\"\"\n    is_three_black_crows = (df['close'] < df['open']) & (df['close'].shift(1) < df['open'].shift(1)) & (df['close'].shift(2) < df['open'].shift(2)) & \\\n                           (abs(df['close'] - df['open']) > body_threshold * (df['high'] - df['low'])) & \\\n                           (abs(df['close'].shift(1) - df['open'].shift(1)) > body_threshold * (df['high'].shift(1) - df['low'].shift(1))) & \\\n                           (abs(df['close'].shift(2) - df['open'].shift(2)) > body_threshold * (df['high'].shift(2) - df['low'].shift(2)))\n\n    return is_three_black_crows\n\n\n\ndef do_calculate_evening_star(df: pd.DataFrame, body_threshold: float = 0.1) -> pd.Series:\n    \"\"\"\n    Detects Evening Star pattern (simplified).\n\n    Args:\n        df: DataFrame with OHLC data.\n        body_threshold: Minimum body size ratio compared to the previous candle's body size.\n\n    Returns:\n        pandas.Series: Boolean Series indicating Evening Star patterns.\n    \"\"\"\n    is_evening_star = (df['close'].shift(2) > df['open'].shift(2)) & (df['close'].shift(1) > df['open'].shift(1)) & (df['close'] < df['open']) & (abs(df['close'] - df['open']) > body_threshold * abs(df['close'].shift(1) - df['open'].shift(1)) )\n\n    return is_evening_star\n\n\ndef do_calculate_upside_tasuki_gap(df: pd.DataFrame, gap_threshold: float = 0.01) -> pd.Series:\n    \"\"\"\n    Detects Upside Tasuki Gap pattern (simplified).\n\n    Args:\n        df: DataFrame with OHLC data.\n        gap_threshold: Minimum gap size as percentage of the previous candle's range.\n\n    Returns:\n        pandas.Series: Boolean Series indicating Upside Tasuki Gap patterns.\n    \"\"\"\n    is_upside_tasuki_gap = (df['open'] > df['close'].shift(1)) & (df['close'] < df['open']) & (df['open'] - df['close'].shift(1) > gap_threshold * (df['high'].shift(1) - df['low'].shift(1)))\n\n    return is_upside_tasuki_gap\n\n\ndef do_calculate_inverted_hammer(df: pd.DataFrame, wick_body_ratio: float = 2.0) -> pd.Series:\n    \"\"\"\n    Detects Inverted Hammer pattern.\n\n    Args:\n        df: DataFrame with OHLC data.\n        wick_body_ratio: Minimum ratio of upper wick length to body size.\n\n    Returns:\n        pandas.Series: Boolean Series indicating Inverted Hammer patterns.\n    \"\"\"\n    body = abs(df['close'] - df['open'])\n    upper_wick = df['high'] - max(df['open'], df['close'])\n    lower_wick = min(df['open'], df['close']) - df['low']\n\n    is_inverted_hammer = (body > 0) & (upper_wick >= wick_body_ratio * body) & (lower_wick <= body / 2)\n\n    return is_inverted_hammer\n\n\n\ndef do_calculate_matching_low(df: pd.DataFrame, low_diff_threshold: float = 0.001) -> pd.Series:\n    \"\"\"\n    Detects Matching Low pattern.\n\n    Args:\n      df: DataFrame with OHLC data.\n      low_diff_threshold: Maximum difference (as fraction) between current and previous lows for a match.\n\n    Returns:\n      pandas.Series: Boolean Series indicating Matching Low patterns.\n    \"\"\"\n\n    is_matching_low = (abs(df['low'] - df['low'].shift(1)) <= low_diff_threshold * df['low'])\n\n    return is_matching_low\n\n\n\ndef do_calculate_bullish_abandoned_baby(df: pd.DataFrame, gap_threshold: float = 0.01) -> pd.Series:\n    \"\"\"\n    Detects Bullish Abandoned Baby pattern (simplified).\n\n    Args:\n        df: DataFrame with OHLC data.\n        gap_threshold: Minimum gap as percentage of the previous candle's range.\n\n    Returns:\n        pandas.Series: Boolean Series indicating Bullish Abandoned Baby patterns.\n    \"\"\"\n    prev_high = df['high'].shift(1)\n    prev_low = df['low'].shift(1)\n    prev_range = prev_high - prev_low\n\n    is_bullish_abandoned_baby = (df['open'] < df['close'].shift(1)) & (df['close'] > df['open']) & (df['low'] > prev_high) & (df['high'] < prev_low + prev_range * (1 + gap_threshold))\n\n    return is_bullish_abandoned_baby\n\n\ndef do_calculate_two_black_gapping(df: pd.DataFrame, gap_threshold: float = 0.01) -> pd.Series:\n    \"\"\"\n    Detects Two Black Gapping pattern (simplified).\n\n    Args:\n        df: DataFrame with OHLC data.\n        gap_threshold: Minimum gap size as a percentage of the previous candle's range.\n\n    Returns:\n        pandas.Series: Boolean Series indicating Two Black Gapping patterns.\n    \"\"\"\n    is_two_black_gapping = (df['open'] < df['close'].shift(1)) & (df['close'] < df['open']) & (df['open'].shift(1) < df['close'].shift(2)) & (df['close'].shift(1) < df['open'].shift(1)) & (df['open'] - df['close'].shift(1) > gap_threshold * (df['high'].shift(1) - df['low'].shift(1)))\n\n    return is_two_black_gapping\n\n\n\ndef do_calculate_bearish_breakaway(df: pd.DataFrame, range_threshold: float = 0.03) -> pd.Series:\n    \"\"\"\n    Detects Bearish Breakaway pattern (simplified).\n\n    Args:\n        df: DataFrame with OHLC data.\n        range_threshold: Minimum percentage move beyond the previous range.\n\n    Returns:\n        pandas.Series: Boolean Series indicating Bearish Breakaway patterns.\n    \"\"\"\n    prev_high = df['high'].shift(1)\n    prev_low = df['low'].shift(1)\n    prev_range = prev_high - prev_low\n\n    is_bearish_breakaway = (df['close'] < prev_low - range_threshold * prev_range)\n\n    return is_bearish_breakaway\n\n\"\"\"\nImportant Notes:\n\nSimplifications: These functions are simplified representations of the patterns. Real-world identification often needs more complex logic and potentially additional conditions. Fine-tuning parameters will be critical for accurate pattern detection in your specific data.\nParameter Tuning: Experiment with different values for parameters (gap_threshold, body_threshold, wick_body_ratio, etc.) to optimize performance for your data.\nVisual Verification: Always visually confirm the patterns identified by the functions. Automated detection can produce false positives or negatives.\nContext Matters: Candlestick patterns are most useful in conjunction with other technical indicators and analysis. Do not base trading decisions solely on automated pattern recognition.\nRemember to thoroughly test these functions with your own data and refine them as needed. These functions are provided as a starting point; you will likely need to further adapt them for optimal performance within your trading strategy.\n\"\"\"\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T19:38:32.544988Z","iopub.execute_input":"2025-03-12T19:38:32.545303Z","iopub.status.idle":"2025-03-12T19:38:32.692570Z","shell.execute_reply.started":"2025-03-12T19:38:32.545275Z","shell.execute_reply":"2025-03-12T19:38:32.691482Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"'\\nImportant Notes:\\n\\nSimplifications: These functions are simplified representations of the patterns. Real-world identification often needs more complex logic and potentially additional conditions. Fine-tuning parameters will be critical for accurate pattern detection in your specific data.\\nParameter Tuning: Experiment with different values for parameters (gap_threshold, body_threshold, wick_body_ratio, etc.) to optimize performance for your data.\\nVisual Verification: Always visually confirm the patterns identified by the functions. Automated detection can produce false positives or negatives.\\nContext Matters: Candlestick patterns are most useful in conjunction with other technical indicators and analysis. Do not base trading decisions solely on automated pattern recognition.\\nRemember to thoroughly test these functions with your own data and refine them as needed. These functions are provided as a starting point; you will likely need to further adapt them for optimal performance within your trading strategy.\\n'"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"class OptimizerDefinition:\n    def __init__(self, name: str, parameters: typing.Dict[str, \"ParameterType\"], optimization_function, factory=None): \n        if not isinstance(name, str):\n            raise TypeError(\"name must be a string\")\n\n        if not isinstance(parameters, dict):\n            raise TypeError(\"parameters must be a dictionary\")\n\n        if not all(isinstance(param, ParameterType) for param in parameters.values()):\n            raise TypeError(\"All values in parameters must be ParameterType objects\")\n\n        if len(set(parameters.keys())) != len(parameters.keys()): # Check for duplicate keys\n            raise ValueError(\"Parameter names must be unique.\")\n\n        if not callable(calculation_function):\n            raise TypeError(\"calculation_function must be callable\")\n\n        self.name = name\n        self.parameters = parameters\n        self.calculation_function = calculation_function\n        self.factory = factory\n\n    def create_optimizer(self, **kwargs: typing.Any):\n        params = {}\n        for name, param_def in self.parameters.items():\n            value = kwargs.get(name)\n\n            if value is None:\n                value = param_def.get_default()\n\n            if param_def.data_type == \"integer\" and not isinstance(value, int):\n                raise TypeError(f\"Value for parameter '{name}' must be an integer\")\n            elif param_def.data_type == \"real\" and not isinstance(value, (int, float)):\n                raise TypeError(f\"Value for parameter '{name}' must be a number\")\n            elif param_def.data_type == \"boolean\" and not isinstance(value, bool):\n                raise TypeError(f\"Value for parameter '{name}' must be a boolean\")\n            elif param_def.data_type == \"string\" and not isinstance(value, str):\n                raise TypeError(f\"Value for parameter '{name}' must be a string\")\n            elif param_def.data_type in (\"integer\", \"real\"):\n                if param_def.min_val is not None and value < param_def.min_val:  # Check min_val\n                    raise ValueError(f\"Value for parameter '{name}' must be greater than or equal to {param_def.min_val}\")\n                if param_def.max_val is not None and value > param_def.max_val:  # Check max_val\n                    raise ValueError(f\"Value for parameter '{name}' must be less than or equal to {param_def.max_val}\")\n\n            if param_def.data_type == \"string\" and param_def.allowed_strings is not None and value not in param_def.allowed_strings:\n                raise ValueError(f\"Value {value} is not in allowed strings for parameter {name}\")\n\n            params[name] = value\n\n        return OptimizerInstance(self.name, params, self)\n\n    def calculate(self, data: pd.DataFrame, params: typing.Dict[str, typing.Any]) -> pd.DataFrame:\n        \"\"\"\n        Calculates the optimization using the provided data and parameters.\n        \"\"\"\n        kwargs = params.copy() \n        return self.optimization_function(data, **kwargs)\n\n    def __repr__(self):\n        return f\"OptimizerDefinition(name='{self.name}', parameters={self.parameters}, calculation_function={self.calculation_function.__name__ if hasattr(self.calculation_function, '__name__') else str(self.calculation_function)}, factory={self.factory})\"","metadata":{"_uuid":"81d12825-5fa3-47ef-89ad-eeac27ccc325","_cell_guid":"44bf1c17-21ad-4200-9485-16397403472f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-12T19:38:32.693555Z","iopub.execute_input":"2025-03-12T19:38:32.693920Z","iopub.status.idle":"2025-03-12T19:38:32.708336Z","shell.execute_reply.started":"2025-03-12T19:38:32.693882Z","shell.execute_reply":"2025-03-12T19:38:32.707065Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"","metadata":{"_uuid":"6ff05d14-4764-4926-aad2-6de123acf599","_cell_guid":"2dd61585-7a51-4e4d-89a5-0e56e86f2a0e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"_uuid":"3eb9f5ba-fcc3-4525-a072-eb820aa697b0","_cell_guid":"77b4278f-d414-40c9-886a-feda80123db2","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}