{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93ea3305",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-15T07:22:24.506905Z",
     "iopub.status.busy": "2025-02-15T07:22:24.506537Z",
     "iopub.status.idle": "2025-02-15T07:22:24.511384Z",
     "shell.execute_reply": "2025-02-15T07:22:24.510405Z"
    },
    "papermill": {
     "duration": 0.014307,
     "end_time": "2025-02-15T07:22:24.512856",
     "exception": false,
     "start_time": "2025-02-15T07:22:24.498549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Notebook for performing technical analysis and backtesting on Sharadar data (alpha)\n",
    "\n",
    "# Note: this was originally written largely with the assistance of Gemini,\n",
    "# although it needed a lot of extra prompting. I generated\n",
    "# the grammar and reification modules by hand and extensively refactored the generated code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c399061",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T07:22:24.525636Z",
     "iopub.status.busy": "2025-02-15T07:22:24.525313Z",
     "iopub.status.idle": "2025-02-15T07:22:25.453582Z",
     "shell.execute_reply": "2025-02-15T07:22:25.452483Z"
    },
    "papermill": {
     "duration": 0.936705,
     "end_time": "2025-02-15T07:22:25.455529",
     "exception": false,
     "start_time": "2025-02-15T07:22:24.518824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import typing\n",
    "import unittest\n",
    "import abc\n",
    "import re\n",
    "import typing\n",
    "import inspect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2356b565",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T07:22:25.468423Z",
     "iopub.status.busy": "2025-02-15T07:22:25.467883Z",
     "iopub.status.idle": "2025-02-15T07:22:25.483750Z",
     "shell.execute_reply": "2025-02-15T07:22:25.482660Z"
    },
    "papermill": {
     "duration": 0.024224,
     "end_time": "2025-02-15T07:22:25.485655",
     "exception": false,
     "start_time": "2025-02-15T07:22:25.461431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/INDICATORS.csv\n",
      "/kaggle/input/SP500.csv\n",
      "/kaggle/input/METRICS.csv\n",
      "/kaggle/input/SF1.csv\n",
      "/kaggle/input/SFP.csv\n",
      "/kaggle/input/TICKERS.csv\n",
      "/kaggle/input/SEP.csv\n",
      "/kaggle/input/DAILY.csv\n",
      "/kaggle/input/SF3B.csv\n",
      "/kaggle/input/__notebook__.ipynb\n",
      "/kaggle/input/SF3.csv\n",
      "/kaggle/input/SF2.csv\n",
      "/kaggle/input/ACTIONS.csv\n",
      "/kaggle/input/EVENTS.csv\n",
      "/kaggle/input/SF3A.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff42be68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T07:22:25.498877Z",
     "iopub.status.busy": "2025-02-15T07:22:25.498548Z",
     "iopub.status.idle": "2025-02-15T07:22:25.503356Z",
     "shell.execute_reply": "2025-02-15T07:22:25.502310Z"
    },
    "papermill": {
     "duration": 0.013317,
     "end_time": "2025-02-15T07:22:25.505132",
     "exception": false,
     "start_time": "2025-02-15T07:22:25.491815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Token:\n",
    "    def __init__(self, type: str, value: str):\n",
    "        self.type = type\n",
    "        self.value = value\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Token({self.type}, '{self.value}')\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0375e37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T07:22:25.518500Z",
     "iopub.status.busy": "2025-02-15T07:22:25.518095Z",
     "iopub.status.idle": "2025-02-15T07:22:25.536812Z",
     "shell.execute_reply": "2025-02-15T07:22:25.535616Z"
    },
    "papermill": {
     "duration": 0.027578,
     "end_time": "2025-02-15T07:22:25.538689",
     "exception": false,
     "start_time": "2025-02-15T07:22:25.511111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ParseTreeNode:\n",
    "    def __init__(self, type: str, value: typing.Optional[str] = None, children: typing.Optional[typing.List[\"ParseTreeNode\"]] = None):\n",
    "        self.type = type\n",
    "        self.value = value\n",
    "        self.children = children or []\n",
    "        self.start_index = None\n",
    "        self.end_index = None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"ParseTreeNode({self.type}, value={self.value}, children={self.children}, start_index={self.start_index}, end_index={self.end_index})\"\n",
    "    def reify(self, function_factory):\n",
    "        if (self.type == \"expression\") and len(self.children) == 3 and self.children[0].type == \"term\" and self.children[1].value == \"+\" and self.children[2].type == \"term\":\n",
    "            return self.children[0].reify(function_factory) + self.children[2].reify(function_factory)\n",
    "        # TODO: this isn't quite right\n",
    "        if (self.type == \"expression\") and len(self.children) == 3 and self.children[0].type == \"term\" and self.children[1].value == \"-\" and self.children[2].type == \"term\":\n",
    "            return self.children[0].reify(function_factory) - self.children[2].reify(function_factory)  \n",
    "        if(self.type == \"expression\") and len(self.children) == 1:\n",
    "            return self.children[0].reify(function_factory)\n",
    "        if (self.type == \"expression\") and len(self.children) == 3 and self.children[0].type == \"term\" and self.children[1].value == \"*\" and self.children[2].type == \"term\":\n",
    "            return self.children[0].reify(function_factory) * self.children[2].reify(function_factory)            \n",
    "        # TODO: this isn't quite right\n",
    "        if (self.type == \"expression\") and len(self.children) == 3 and self.children[0].type == \"term\" and self.children[1].value == \"/\" and self.children[2].type == \"term\":\n",
    "            return self.children[0].reify(function_factory) / self.children[2].reify(function_factory)     \n",
    "        if self.type == \"term\" and len(self.children) == 1:\n",
    "            return self.children[0].reify(function_factory)\n",
    "        if self.type == \"factor\" and len(self.children) == 1:\n",
    "            return self.children[0].reify(function_factory)\n",
    "        if self.type == \"factor\" and len(self.children) == 3 and self.children[0].value == \"(\" and self.children[2].value == \")\":\n",
    "            return self.children[1].reify(function_factory)\n",
    "        if self.type == \"number\" and self.children is None or len(self.children) == 0:\n",
    "            try:\n",
    "                return int(self.value)\n",
    "            except:\n",
    "                return float(self.value)\n",
    "        if self.type == \"string\" and self.children is None or len(self.children) == 0:\n",
    "            return self.value\n",
    "            \n",
    "        if self.type == \"factor\" and len(self.children) == 4 and self.children[0].type == \"identifier\" and self.children[1].value == \"(\" and self.children[2].type == \"arguments\" and self.children[3].value == \")\":\n",
    "\n",
    "            identifier_node = self.children[0]\n",
    "            name = identifier_node.value\n",
    "\n",
    "            try:\n",
    "                definition = function_factory.get(name)\n",
    "            except ValueError:\n",
    "                raise ValueError(f\"Function '{name}' not found in the factory.\")\n",
    "\n",
    "            params = {}\n",
    "\n",
    "            arguments_node = self.children[2]\n",
    "            param_index = 0\n",
    "            param_names = list(definition.parameters.keys())\n",
    "\n",
    "            # Handle named arguments FIRST\n",
    "            named_params_processed = set()  # Keep track of named params\n",
    "\n",
    "            for argument_node in arguments_node.children:\n",
    "                if len(argument_node.children) == 3 and argument_node.children[1].type == \"operator\" and argument_node.children[1].value == \"=\":\n",
    "                    param_name = argument_node.children[0].value\n",
    "                    param_value_node = argument_node.children[2]\n",
    "\n",
    "                    if param_name in named_params_processed: # Skip already processed named parameters\n",
    "                        continue\n",
    "\n",
    "                    try:\n",
    "                        param_def = definition.parameters[param_name]\n",
    "                    except KeyError:\n",
    "                        raise ValueError(f\"Parameter '{param_name}' not found for indicator '{name}'.\")\n",
    "\n",
    "                    param_value = param_value_node.reify(function_factory)  # Evaluate the value node\n",
    "                    params[param_name] = param_value\n",
    "                    named_params_processed.add(param_name) # Add to the set of processed named parameters\n",
    "\n",
    "            # Then handle positional arguments (skipping already named ones)\n",
    "            for argument_node in arguments_node.children:\n",
    "                if len(argument_node.children) == 1:  # Positional argument\n",
    "                    try:\n",
    "                        param_name = param_names[param_index]\n",
    "                        if param_name in named_params_processed: # Skip if already named\n",
    "                            param_index += 1\n",
    "                            continue\n",
    "\n",
    "                        param_def = definition.parameters[param_name]\n",
    "                    except IndexError:\n",
    "                        raise ValueError(f\"Incorrect number of positional parameters for '{name}'.\")\n",
    "\n",
    "                    param_value_node = argument_node.children[0]\n",
    "                    param_value = param_value_node.reify(function_factory)\n",
    "                    params[param_name] = param_value\n",
    "                    param_index += 1\n",
    "\n",
    "\n",
    "\n",
    "            required_params = set(definition.parameters.keys())\n",
    "            provided_params = set(params.keys())\n",
    "            if required_params != provided_params:\n",
    "                missing = required_params - provided_params\n",
    "                raise ValueError(f\"Missing required parameters for {name}: {missing}\")\n",
    "\n",
    "            return definition.create_function(**params)\n",
    "\n",
    "        raise ValueError(f\"Cannot reify node of type: {self.type} with {len(self.children)} children: {self}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1512e88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T07:22:25.552021Z",
     "iopub.status.busy": "2025-02-15T07:22:25.551641Z",
     "iopub.status.idle": "2025-02-15T07:22:25.556653Z",
     "shell.execute_reply": "2025-02-15T07:22:25.555532Z"
    },
    "papermill": {
     "duration": 0.01369,
     "end_time": "2025-02-15T07:22:25.558306",
     "exception": false,
     "start_time": "2025-02-15T07:22:25.544616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GrammarRule:\n",
    "    def __init__(self, left: str, right: typing.List[str]):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.left} -> {' '.join(self.right)}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "805c1c07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T07:22:25.571603Z",
     "iopub.status.busy": "2025-02-15T07:22:25.571264Z",
     "iopub.status.idle": "2025-02-15T07:22:25.587681Z",
     "shell.execute_reply": "2025-02-15T07:22:25.586524Z"
    },
    "papermill": {
     "duration": 0.025071,
     "end_time": "2025-02-15T07:22:25.589388",
     "exception": false,
     "start_time": "2025-02-15T07:22:25.564317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Grammar:\n",
    "    def __init__(self, grammar_string: str):\n",
    "        \"\"\"Initializes a Grammar object by parsing the grammar string.\"\"\"\n",
    "        self.rules = []\n",
    "        for line in grammar_string.strip().splitlines():\n",
    "            if line.strip():  # Skip empty lines\n",
    "                parts = line.split(\"->\")\n",
    "                if len(parts) != 2:\n",
    "                    raise ValueError(f\"Invalid grammar rule: {line}\")\n",
    "                left = parts[0].strip()\n",
    "                right = [part.strip() for part in parts[1].split()]\n",
    "                self.rules.append(GrammarRule(left, right))  # Store rules as attributes\n",
    "\n",
    "\n",
    "    def build_parse_tree(self, tokens: typing.List[\"Token\"], start_symbol: str = \"expression\") -> typing.Optional[\"ParseTreeNode\"]:\n",
    "        \"\"\"Builds a parse tree from a list of tokens using the grammar rules.\"\"\"\n",
    "\n",
    "        def _parse(index: int, nonterminal: str, current_depth=0) -> typing.Optional[\"ParseTreeNode\"]:\n",
    "            applicable_rules = [rule for rule in self.rules if rule.left == nonterminal]\n",
    "\n",
    "            if index >= len(tokens):  # End of tokens\n",
    "                if any(not rule.right for rule in applicable_rules): # Check for a matching epsilon rule\n",
    "                    return ParseTreeNode(nonterminal, children=[])\n",
    "                return None # No matching epsilon rule\n",
    "\n",
    "            if not applicable_rules:\n",
    "                return None\n",
    "\n",
    "            for rule in applicable_rules:\n",
    "                rule_matched = True\n",
    "                children = []\n",
    "                current_index = index\n",
    "\n",
    "                for symbol in rule.right:\n",
    "                    if current_index >= len(tokens):\n",
    "                        rule_matched = False\n",
    "                        break\n",
    "\n",
    "                    if current_index < len(tokens):\n",
    "                        token = tokens[current_index]\n",
    "\n",
    "                        if (symbol == token.type) or (symbol == f'\"{token.value}\"') or \\\n",
    "                           (symbol == \"identifier\" and token.type == \"identifier\") or \\\n",
    "                           (symbol == \"number\" and token.type == \"number\") or \\\n",
    "                           (symbol == \"string\" and token.type == \"string\") or \\\n",
    "                           (symbol == \"operator\" and token.type == \"operator\"):\n",
    "                            child = ParseTreeNode(token.type, value=token.value)\n",
    "                            child.start_index = current_index\n",
    "                            child.end_index = current_index\n",
    "                            children.append(child)\n",
    "                            current_index += 1  # Increment for terminal\n",
    "\n",
    "                        elif any(gr.left == symbol for gr in self.rules):\n",
    "                            child_node = _parse(current_index, symbol, current_depth + 1)\n",
    "                            if child_node:\n",
    "                                children.append(child_node)\n",
    "                                current_index = child_node.end_index + 1\n",
    "                            else:\n",
    "                                rule_matched = False\n",
    "                                break\n",
    "\n",
    "                        else:\n",
    "                            rule_matched = False\n",
    "                            break\n",
    "\n",
    "                if rule_matched:\n",
    "                    node = ParseTreeNode(nonterminal, children=children)\n",
    "                    node.start_index = children[0].start_index if children else index # Handle epsilon rules where children is empty\n",
    "                    node.end_index = children[-1].end_index if children else index -1 # Handle epsilon rules where children is empty\n",
    "\n",
    "                    return node\n",
    "\n",
    "            return None\n",
    "\n",
    "        return _parse(0, start_symbol)  # Allow specifying the start symbol\n",
    "        \n",
    "    def parse(self, input_string: str, start_symbol: str = \"expression\"):\n",
    "        \"\"\"Parses an input string into a parse tree.\"\"\"\n",
    "        tokens = self.tokenize(input_string)  # Tokenize the input string\n",
    "        return self.build_parse_tree(tokens, start_symbol)\n",
    "\n",
    "    def tokenize(self, expression: str) -> typing.List[Token]:\n",
    "        \"\"\"\n",
    "        Tokenizes a string expression, splitting on spaces and identifying operators.\n",
    "        \"\"\"\n",
    "    \n",
    "        # Corrected regular expression pattern:\n",
    "        pattern = r\"(\\*\\*|\\*|/|//|%|\\+|-|==|!=|<=|>=|<|>|=|!|&&|\\|\\||&|\\||\\^|~|<<|>>|\\(|\\)|\\[|\\]|\\{|\\}|,|:|\\.|->|@|=|;|\\+=|-=|\\*=|/=|//=|%=|&=|\\|=|\\^=|\\<<=|>>=)|'([^']+)'|\\\"([^\\\"]+)\\\"|(\\d+\\.?\\d*)|([a-zA-Z_]\\w*)\"\n",
    "    \n",
    "        tokens = []\n",
    "        for match in re.finditer(pattern, expression):\n",
    "            operator_match = match.group(1)\n",
    "            single_quote_match = match.group(2)\n",
    "            double_quote_match = match.group(3)\n",
    "            number_match = match.group(4)\n",
    "            identifier_match = match.group(5)\n",
    "    \n",
    "            if operator_match:\n",
    "                tokens.append(Token(\"operator\", operator_match))\n",
    "            elif single_quote_match:\n",
    "                tokens.append(Token(\"string\", single_quote_match))\n",
    "            elif double_quote_match:\n",
    "                tokens.append(Token(\"string\", double_quote_match))\n",
    "            elif number_match:\n",
    "                tokens.append(Token(\"number\", number_match))\n",
    "            elif identifier_match:\n",
    "                tokens.append(Token(\"identifier\", identifier_match))\n",
    "            else:\n",
    "                raise ValueError(f\"invalid token in {expression}\")\n",
    "    \n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3144a73",
   "metadata": {
    "papermill": {
     "duration": 0.005505,
     "end_time": "2025-02-15T07:22:25.600779",
     "exception": false,
     "start_time": "2025-02-15T07:22:25.595274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7757d5",
   "metadata": {
    "papermill": {
     "duration": 0.005315,
     "end_time": "2025-02-15T07:22:25.611696",
     "exception": false,
     "start_time": "2025-02-15T07:22:25.606381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c79c2d40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T07:22:25.624285Z",
     "iopub.status.busy": "2025-02-15T07:22:25.623902Z",
     "iopub.status.idle": "2025-02-15T07:22:25.629861Z",
     "shell.execute_reply": "2025-02-15T07:22:25.628560Z"
    },
    "papermill": {
     "duration": 0.014173,
     "end_time": "2025-02-15T07:22:25.631541",
     "exception": false,
     "start_time": "2025-02-15T07:22:25.617368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FunctionInstance:\n",
    "    def __init__(self, name: str, parameters: typing.Dict[str, typing.Any], definition):\n",
    "        self.name = name\n",
    "        self.parameters = parameters\n",
    "        self.definition = definition\n",
    "\n",
    "    def calculate(self, data: pd.DataFrame): \n",
    "        \"\"\"\n",
    "        Screens the data using the screener's definition and parameters.\n",
    "\n",
    "        Args:\n",
    "            data: The Pandas DataFrame containing the data.\n",
    "\n",
    "        Returns:\n",
    "            A Pandas Dataframe\n",
    "        \"\"\"\n",
    "        return self.definition.calculate(data, self.parameters) # Pass the date to the definition\n",
    "\n",
    "    def __repr__(self):\n",
    "        params_str = \", \".join(f\"{name}={value}\" for name, value in self.parameters.items())\n",
    "        return f\"{self.definition.name}({params_str})\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6dd610c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T07:22:25.644979Z",
     "iopub.status.busy": "2025-02-15T07:22:25.644646Z",
     "iopub.status.idle": "2025-02-15T07:22:25.657689Z",
     "shell.execute_reply": "2025-02-15T07:22:25.656830Z"
    },
    "papermill": {
     "duration": 0.021858,
     "end_time": "2025-02-15T07:22:25.659526",
     "exception": false,
     "start_time": "2025-02-15T07:22:25.637668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Parameter:\n",
    "    \"\"\"\n",
    "    A class for specifying parameters for screeners and indicators.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 name: str,\n",
    "                 data_type: typing.Literal[\"integer\", \"real\", \"boolean\", \"string\"],\n",
    "                 min_val: typing.Union[int, float, None] = None,\n",
    "                 max_val: typing.Union[int, float, None] = None,\n",
    "                 default: typing.Any = None,\n",
    "                 timeframe_defaults: typing.Dict[typing.Literal[\"tick\", \"1s\", \"5s\", \"15s\", \"1m\", \"2m\", \"5m\", \"15m\", \"1d\", \"1w\", \"1M\"], typing.Any] = None,\n",
    "                 increment: typing.Union[int, float, None] = None,\n",
    "                 allowed_strings: typing.List[str] | None = None):\n",
    "        if not isinstance(name, str):\n",
    "            raise TypeError(\"name must be a string\")\n",
    "        if data_type not in (\"integer\", \"real\", \"boolean\", \"string\"):\n",
    "            raise ValueError(\"data_type must be 'integer', 'real', 'boolean', or 'string'\")\n",
    "\n",
    "        if min_val is not None:\n",
    "            if data_type == \"integer\" and not isinstance(min_val, int):\n",
    "                raise TypeError(\"min_val must be an integer for integer data_type\")\n",
    "            elif data_type in (\"real\", \"integer\") and not isinstance(min_val, (int, float)):\n",
    "                raise TypeError(\"min_val must be a number for real or integer data_type\")\n",
    "\n",
    "        if max_val is not None:\n",
    "            if data_type == \"integer\" and not isinstance(max_val, int):\n",
    "                raise TypeError(\"max_val must be an integer for integer data_type\")\n",
    "            elif data_type in (\"real\", \"integer\") and not isinstance(max_val, (int, float)):\n",
    "                raise TypeError(\"max_val must be a number for real or integer data_type\")\n",
    "\n",
    "        if timeframe_defaults is not None:\n",
    "            if not isinstance(timeframe_defaults, dict):\n",
    "                raise TypeError(\"timeframe_defaults must be a dictionary\")\n",
    "            for timeframe in timeframe_defaults:\n",
    "                if timeframe not in (\"tick\", \"1s\", \"5s\", \"15s\", \"1m\", \"2m\", \"5m\", \"15m\", \"1d\", \"1w\", \"1M\"):\n",
    "                    raise ValueError(f\"Invalid timeframe: {timeframe}\")\n",
    "\n",
    "        if data_type == \"integer\" and increment is None:\n",
    "            increment = 1\n",
    "        elif data_type == \"real\" and increment is None:\n",
    "            increment = 0.01\n",
    "\n",
    "        if data_type == \"string\" and allowed_strings is not None and not isinstance(allowed_strings, list):\n",
    "          raise TypeError(\"allowed_strings must be a list of strings\")\n",
    "\n",
    "        if data_type != \"string\" and allowed_strings is not None:\n",
    "          raise ValueError(\"allowed_strings can only be specified for string data type\")\n",
    "\n",
    "\n",
    "        self.name = name\n",
    "        self.data_type = data_type\n",
    "        self.min_val = min_val\n",
    "        self.max_val = max_val\n",
    "        self.default = default\n",
    "        self.timeframe_defaults = timeframe_defaults or {}\n",
    "        self.increment = increment\n",
    "        self.allowed_strings = allowed_strings\n",
    "\n",
    "    def get_default(self) -> typing.Any:\n",
    "        return self.default\n",
    "\n",
    "    def get_possible_values(self) -> typing.Iterable[typing.Any]:\n",
    "        if self.data_type == \"integer\":\n",
    "            if self.min_val is not None and self.max_val is not None:\n",
    "                return range(self.min_val, self.max_val + 1)\n",
    "        elif self.data_type == \"real\":\n",
    "            if self.min_val is not None and self.max_val is not None:\n",
    "                current = self.min_val\n",
    "                while current <= self.max_val:\n",
    "                    yield current\n",
    "                    current += 0.01\n",
    "        elif self.data_type == \"boolean\":\n",
    "            return [True, False]\n",
    "        elif self.data_type == \"string\":\n",
    "            if self.allowed_strings is not None:  # Check if allowed_strings is defined\n",
    "                return self.allowed_strings  # If defined, return those values\n",
    "            else:\n",
    "                return []  # Return an empty list if allowed_strings is None (unrestricted)\n",
    "        return []\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Parameter(name='{self.name}', data_type='{self.data_type}', min_val={self.min_val}, max_val={self.max_val}, default={self.default}, allowed_strings={self.allowed_strings})\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eaeccbf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T07:22:25.672339Z",
     "iopub.status.busy": "2025-02-15T07:22:25.671978Z",
     "iopub.status.idle": "2025-02-15T07:22:25.682794Z",
     "shell.execute_reply": "2025-02-15T07:22:25.681873Z"
    },
    "papermill": {
     "duration": 0.01888,
     "end_time": "2025-02-15T07:22:25.684439",
     "exception": false,
     "start_time": "2025-02-15T07:22:25.665559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FunctionDefinition:\n",
    "    def __init__(self, name: str, parameters: typing.Dict[str, \"Parameter\"], calculation_function, factory=None): \n",
    "        if not isinstance(name, str):\n",
    "            raise TypeError(\"name must be a string\")\n",
    "\n",
    "        if not isinstance(parameters, dict):\n",
    "            raise TypeError(\"parameters must be a dictionary\")\n",
    "\n",
    "        if not all(isinstance(param, Parameter) for param in parameters.values()):\n",
    "            raise TypeError(\"All values in parameters must be Parameter objects\")\n",
    "\n",
    "        if len(set(parameters.keys())) != len(parameters.keys()): # Check for duplicate keys\n",
    "            raise ValueError(\"Parameter names must be unique.\")\n",
    "\n",
    "        if not callable(calculation_function):\n",
    "            raise TypeError(\"calculation_function must be callable\")\n",
    "\n",
    "        self.name = name\n",
    "        self.parameters = parameters\n",
    "        self.calculation_function = calculation_function\n",
    "        self.factory = factory\n",
    "\n",
    "    def create_function(self, **kwargs: typing.Any) -> \"FunctionInstance\":\n",
    "        params = {}\n",
    "        for name, param_def in self.parameters.items():\n",
    "            value = kwargs.get(name)\n",
    "\n",
    "            if value is None:\n",
    "                value = param_def.get_default()\n",
    "\n",
    "            if param_def.data_type == \"integer\" and not isinstance(value, int):\n",
    "                raise TypeError(f\"Value for parameter '{name}' must be an integer\")\n",
    "            elif param_def.data_type == \"real\" and not isinstance(value, (int, float)):\n",
    "                raise TypeError(f\"Value for parameter '{name}' must be a number\")\n",
    "            elif param_def.data_type == \"boolean\" and not isinstance(value, bool):\n",
    "                raise TypeError(f\"Value for parameter '{name}' must be a boolean\")\n",
    "            elif param_def.data_type == \"string\" and not isinstance(value, str):\n",
    "                raise TypeError(f\"Value for parameter '{name}' must be a string\")\n",
    "            elif param_def.data_type in (\"integer\", \"real\"):\n",
    "                if param_def.min_val is not None and value < param_def.min_val:  # Check min_val\n",
    "                    raise ValueError(f\"Value for parameter '{name}' must be greater than or equal to {param_def.min_val}\")\n",
    "                if param_def.max_val is not None and value > param_def.max_val:  # Check max_val\n",
    "                    raise ValueError(f\"Value for parameter '{name}' must be less than or equal to {param_def.max_val}\")\n",
    "\n",
    "            if param_def.data_type == \"string\" and param_def.allowed_strings is not None and value not in param_def.allowed_strings:\n",
    "                raise ValueError(f\"Value {value} is not in allowed strings for parameter {name}\")\n",
    "\n",
    "            params[name] = value\n",
    "\n",
    "        return FunctionInstance(self.name, params, self)\n",
    "\n",
    "    def calculate(self, data: pd.DataFrame, params: typing.Dict[str, typing.Any]) -> pd.DataFrame: # Type hint corrected\n",
    "        \"\"\"\n",
    "        Calculates the function using the provided data and parameters.\n",
    "        \"\"\"\n",
    "        kwargs = params.copy() \n",
    "        return self.calculation_function(data, **kwargs)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"FunctionDefinition(name='{self.name}', parameters={self.parameters}, calculation_function={self.calculation_function.__name__ if hasattr(self.calculation_function, '__name__') else str(self.calculation_function)}, factory={self.factory})\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3af9904c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T07:22:25.697232Z",
     "iopub.status.busy": "2025-02-15T07:22:25.696821Z",
     "iopub.status.idle": "2025-02-15T07:22:25.708917Z",
     "shell.execute_reply": "2025-02-15T07:22:25.708014Z"
    },
    "papermill": {
     "duration": 0.020515,
     "end_time": "2025-02-15T07:22:25.710619",
     "exception": false,
     "start_time": "2025-02-15T07:22:25.690104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FunctionFactory:\n",
    "    \"\"\"\n",
    "    A class to manage a suite of function definitions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.function_definitions: typing.Dict[str, Definition] = {}\n",
    "\n",
    "    def register(self, function_definition):\n",
    "        \"\"\"\n",
    "        Registers a new screener definition.\n",
    "\n",
    "        Args:\n",
    "            function_definition: The Definition to register.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If a screener with the same name is already registered.\n",
    "        \"\"\"\n",
    "        if function_definition.name in self.function_definitions:\n",
    "            raise ValueError(f\"A screener with the name '{function_definition.name}' is already registered.\")\n",
    "        self.function_definitions[function_definition.name] = function_definition\n",
    "        function_definition.ffactory = self\n",
    "\n",
    "    def get(self, name: str):\n",
    "        \"\"\"\n",
    "        Retrieves a function definition by name.\n",
    "\n",
    "        Args:\n",
    "            name: The name of the screener.\n",
    "\n",
    "        Returns:\n",
    "            The FunctionDefinition object.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If no screener with the given name is registered.\n",
    "        \"\"\"\n",
    "        if name not in self.function_definitions:\n",
    "            raise ValueError(f\"No function found with the name '{name}'.\")\n",
    "        return self.function_definitions[name]\n",
    "\n",
    "    def parse(self, indicator_string: str) -> FunctionInstance:\n",
    "        \"\"\"\n",
    "        Parses an indicator string and generates an Function object.\n",
    "        Supports both named and positional parameters.\n",
    "\n",
    "        Args:\n",
    "            indicator_string: A string representing the indicator and its parameters, \n",
    "                             e.g., \"SMA(length=20)\", \"RSI(14)\", \"MACD(12, 26, 9)\", \"Bollinger Bands(20, 1.5)\", \"RVWAP(20)\"\n",
    "\n",
    "        Returns:\n",
    "            A Function object.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the indicator string is invalid or if required parameters are missing.\n",
    "            TypeError: If the parameter values are of the wrong type.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            name, params_str = indicator_string.split(\"(\")  # Split name and parameters\n",
    "            name = name.strip()\n",
    "            params_str = params_str[:-1]  # Remove trailing ')'\n",
    "        except ValueError:\n",
    "            raise ValueError(\"Invalid indicator string format. Should be like: IndicatorName(param1=value1, param2=value2, ...) or IndicatorName(value1, value2, ...)\")\n",
    "\n",
    "        try:\n",
    "            definition = self.get(name)  # Get the FunctionDefinition\n",
    "        except ValueError:\n",
    "            raise ValueError(f\"Function '{name}' not found in the factory.\")\n",
    "\n",
    "        params = {}\n",
    "        param_index = 0  # For positional parameters\n",
    "\n",
    "        if params_str:\n",
    "            for param_value_str in params_str.split(\",\"):\n",
    "                param_value_str = param_value_str.strip()\n",
    "\n",
    "                try:\n",
    "                    param_name, param_value = param_value_str.split(\"=\")  # Try to split for named parameters\n",
    "                    param_name = param_name.strip()\n",
    "                    param_value = param_value.strip()\n",
    "\n",
    "                    param_def = definition.parameters.get(param_name)\n",
    "                    if not param_def:\n",
    "                        raise ValueError(f\"Parameter '{param_name}' not found for function '{name}'.\")\n",
    "\n",
    "                except ValueError:  # Positional parameter\n",
    "                    param_name = list(definition.parameters.keys())[param_index]  # Get parameter name by index\n",
    "                    param_def = definition.parameters[param_name] # Get the definition\n",
    "                    param_value = param_value_str\n",
    "\n",
    "                if param_def.data_type == \"integer\":\n",
    "                    try:\n",
    "                        param_value = int(param_value)\n",
    "                    except ValueError:\n",
    "                        raise TypeError(f\"Parameter '{param_name}' must be an integer for function '{name}'.\")\n",
    "                elif param_def.data_type == \"real\":\n",
    "                    try:\n",
    "                        param_value = float(param_value)\n",
    "                    except ValueError:\n",
    "                        raise TypeError(f\"Parameter '{param_name}' must be a float for function '{name}'.\")\n",
    "                elif param_def.data_type == \"boolean\":\n",
    "                    param_value = param_value.lower() == \"true\"\n",
    "                elif param_def.data_type == \"string\":\n",
    "                    param_value = str(param_value)\n",
    "\n",
    "                params[param_name] = param_value\n",
    "                param_index += 1\n",
    "\n",
    "        # Check if all required parameters are provided (both named and positional)\n",
    "        required_params = set(definition.parameters.keys())\n",
    "        provided_params = set(params.keys())\n",
    "        if required_params != provided_params:\n",
    "            missing = required_params - provided_params\n",
    "            raise ValueError(f\"Missing required parameters for {name}: {missing}\")\n",
    "\n",
    "        return definition.create_function(**params)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"FunctionFactory(functions={self.function_definitions})\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2f8b2ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T07:22:25.723822Z",
     "iopub.status.busy": "2025-02-15T07:22:25.723465Z",
     "iopub.status.idle": "2025-02-15T07:22:25.772925Z",
     "shell.execute_reply": "2025-02-15T07:22:25.771784Z"
    },
    "papermill": {
     "duration": 0.058359,
     "end_time": "2025-02-15T07:22:25.774812",
     "exception": false,
     "start_time": "2025-02-15T07:22:25.716453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top N Result:\n",
      "          date symbol  return  other_field\n",
      "0  2024-01-01      A    0.10           10\n",
      "2  2024-01-01      C    0.15           30\n",
      "3  2024-01-02      A    0.12           15\n",
      "5  2024-01-02      C    0.18           35\n",
      "Percentile Result:\n",
      "          date symbol  return  other_field\n",
      "0  2024-01-01      A    0.10           10\n",
      "1  2024-01-01      B    0.05           20\n",
      "3  2024-01-02      A    0.12           15\n",
      "4  2024-01-02      B    0.08           25\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example Screener Functions \n",
    "\n",
    "def top_n_screener_function(df, field, top_n):\n",
    "    \"\"\"\n",
    "    Produces a boolean mask (pd.Series) for the top 5 readings per day.\n",
    "\n",
    "    Args:\n",
    "        df: Pandas DataFrame with columns for date and reading.\n",
    "        date_col: Name of the column containing the date. Should be datetime or convertible.\n",
    "        reading_col: Name of the column containing the reading.\n",
    "\n",
    "    Returns:\n",
    "        A pandas Series (boolean mask) with True for rows corresponding to the \n",
    "        top 5 readings for each day, and False otherwise. Returns\n",
    "        an empty Series if the input DataFrame is empty.\n",
    "    \"\"\"\n",
    "    foo = df.groupby(\"date\")[field].rank(ascending=False, method='first')\n",
    "    mask = foo <= top_n\n",
    "    \n",
    "    return mask\n",
    "\n",
    "\n",
    "def percentile_screener_function(df, field, percentile):\n",
    "    \n",
    "    foo = df.groupby(\"date\")[field].rank(ascending=False, method='first', pct=True)\n",
    "    mask = foo >= percentile\n",
    "    \n",
    "    return mask\n",
    "\n",
    "\n",
    "\n",
    "# Example Usage \n",
    "factory = FunctionFactory()\n",
    "\n",
    "# Top N Screener FunctionDefinition and Registration\n",
    "top_n_field_param = Parameter(\"field\", \"string\", default=\"return\")  # Example allowed strings\n",
    "top_n_n_param = Parameter(\"top_n\", \"integer\", min_val=1, default=5)\n",
    "factory.register(FunctionDefinition(\"TopN\", {\"field\": top_n_field_param, \"top_n\": top_n_n_param}, top_n_screener_function))\n",
    "\n",
    "# Percentile Screener Definition and Registration\n",
    "percentile_field_param = Parameter(\"field\", \"string\", default=\"return\")\n",
    "percentile_percentile_param = Parameter(\"percentile\", \"real\", min_val=0.0, max_val=1.0, default=.1)\n",
    "factory.register(FunctionDefinition(\"Percentile\", {\"field\": percentile_field_param, \"percentile\": percentile_percentile_param}, percentile_screener_function))\n",
    "\n",
    "\n",
    "# Example DataFrame (replace with your data)\n",
    "data = {'date': ['2024-01-01', '2024-01-01', '2024-01-01', '2024-01-02', '2024-01-02', '2024-01-02'],\n",
    "        'symbol': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "        'return': [0.10, 0.05, 0.15, 0.12, 0.08, 0.18],\n",
    "        'other_field': [10, 20, 30, 15, 25, 35]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create and use screeners\n",
    "top_n_screener = factory.parse(\"TopN(top_n=2, field=return)\")\n",
    "top_n_result = top_n_screener.calculate(df)\n",
    "print(\"Top N Result:\\n\", df.loc[top_n_result])\n",
    "\n",
    "percentile_screener = factory.parse(\"Percentile(percentile=.5, field=return)\")\n",
    "percentile_result = percentile_screener.calculate(df)\n",
    "print(\"Percentile Result:\\n\", df.loc[percentile_result])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a9c84aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T07:22:25.787956Z",
     "iopub.status.busy": "2025-02-15T07:22:25.787612Z",
     "iopub.status.idle": "2025-02-15T07:22:25.846372Z",
     "shell.execute_reply": "2025-02-15T07:22:25.845259Z"
    },
    "papermill": {
     "duration": 0.067729,
     "end_time": "2025-02-15T07:22:25.848597",
     "exception": false,
     "start_time": "2025-02-15T07:22:25.780868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMA(length=5)\n",
      "calculate_sma(df, 5)\n",
      "SMA(length=5)\n",
      "RSI(length=14)\n",
      "MACD(fast_length=12, slow_length=26, signal_length=9)\n",
      "RVWAP(length=20)\n",
      "          date symbol   close  volume    high     low  sma(5)    rsi(14)  \\\n",
      "0   2024-01-01    ABC  150.25  100000  152.50  148.00     NaN        NaN   \n",
      "1   2024-01-02    ABC  152.75  120000  155.00  150.50     NaN        NaN   \n",
      "2   2024-01-03    ABC  151.50   80000  153.75  149.25     NaN        NaN   \n",
      "3   2024-01-04    ABC  153.00   90000  155.25  150.75     NaN        NaN   \n",
      "4   2024-01-05    ABC  154.25  110000  156.50  152.00  152.35        NaN   \n",
      "5   2024-01-06    ABC  153.75  100000  156.00  151.50  153.05        NaN   \n",
      "6   2024-01-07    ABC  155.00  150000  157.25  152.75  153.50        NaN   \n",
      "7   2024-01-08    ABC  156.50  160000  158.75  154.25  154.50        NaN   \n",
      "8   2024-01-09    ABC  155.25  130000  157.50  153.00  154.95        NaN   \n",
      "9   2024-01-10    ABC  157.00  110000  159.25  154.75  155.50        NaN   \n",
      "10  2024-01-11    ABC  158.25  120000  160.50  156.00  156.40        NaN   \n",
      "11  2024-01-12    ABC  159.75  140000  162.00  157.50  157.35        NaN   \n",
      "12  2024-01-13    ABC  158.50   90000  160.75  156.25  157.75        NaN   \n",
      "13  2024-01-14    ABC  160.00  100000  162.25  157.75  158.70        NaN   \n",
      "14  2024-01-15    ABC  161.25  130000  163.50  159.00  159.55  78.205128   \n",
      "15  2024-01-16    ABC  160.75  110000  163.00  158.50  160.05  72.857143   \n",
      "16  2024-01-17    ABC  162.00  160000  164.25  159.75  160.50  80.000000   \n",
      "17  2024-01-18    ABC  163.50  170000  165.75  161.25  161.50  80.000000   \n",
      "18  2024-01-19    ABC  162.25  140000  165.50  160.00  161.95  72.857143   \n",
      "19  2024-01-20    ABC  164.00  120000  167.25  161.75  162.50  77.333333   \n",
      "20  2024-01-21    ABC  165.25  130000  168.50  163.00  163.40  77.333333   \n",
      "21  2024-01-22    ABC  166.75  150000  170.00  164.50  164.35  77.333333   \n",
      "22  2024-01-23    ABC  165.50  100000  168.75  163.25  164.75  77.333333   \n",
      "23  2024-01-24    ABC  167.00  110000  170.25  164.75  165.70  77.027027   \n",
      "24  2024-01-25    ABC  168.25  140000  171.50  166.00  166.55  77.027027   \n",
      "25  2024-01-26    ABC  167.75  120000  171.00  165.50  167.05  72.857143   \n",
      "26  2024-01-27    ABC  169.00  170000  172.25  166.75  167.50  80.000000   \n",
      "27  2024-01-28    ABC  170.50  180000  173.75  168.25  168.50  80.000000   \n",
      "28  2024-01-29    ABC  169.25  150000  173.50  167.00  168.95  72.857143   \n",
      "29  2024-01-30    ABC  171.00  130000  175.25  168.75  169.50  77.333333   \n",
      "\n",
      "    macd(12,26,9)   rvwap(20)  \n",
      "0        0.000000         NaN  \n",
      "1        0.199430         NaN  \n",
      "2        0.253691         NaN  \n",
      "3        0.412970         NaN  \n",
      "4        0.632771         NaN  \n",
      "5        0.757882         NaN  \n",
      "6        0.946981         NaN  \n",
      "7        1.204003         NaN  \n",
      "8        1.291937         NaN  \n",
      "9        1.485709         NaN  \n",
      "10       1.720309         NaN  \n",
      "11       2.004166         NaN  \n",
      "12       2.104007         NaN  \n",
      "13       2.277910         NaN  \n",
      "14       2.487915         NaN  \n",
      "15       2.584211         NaN  \n",
      "16       2.729921         NaN  \n",
      "17       2.932630         NaN  \n",
      "18       2.958312         NaN  \n",
      "19       3.084321  157.938957  \n",
      "20       3.247613  158.655488  \n",
      "21       3.458196  159.447791  \n",
      "22       3.484058  159.955511  \n",
      "23       3.584274  160.523715  \n",
      "24       3.721659  161.234049  \n",
      "25       3.747000  161.842700  \n",
      "26       3.823867  162.727244  \n",
      "27       3.960172  163.664440  \n",
      "28       3.922119  164.434028  \n",
      "29       3.987210  165.094925  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  return op(a, b)\n",
      "/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n",
      "  return op(a, b)\n",
      "/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    }
   ],
   "source": [
    "# Indicator Calculation Functions\n",
    "\n",
    "def calculate_sma(df: pd.DataFrame, length: int) -> pd.DataFrame:\n",
    "    print(f\"calculate_sma(df, {length})\")\n",
    "    sma_values = df['close'].rolling(window=length).mean().values\n",
    "    return pd.DataFrame({f\"sma({length})\": sma_values}, index=df.index)\n",
    "\n",
    "def calculate_rsi(df: pd.DataFrame, length: int) -> pd.DataFrame:\n",
    "    length = int(length)\n",
    "    delta = df['close'].diff()\n",
    "    gains = delta.clip(lower=0)\n",
    "    losses = -delta.clip(upper=0)\n",
    "    avg_gains = gains.rolling(window=length).mean()\n",
    "    avg_losses = losses.rolling(window=length).mean()\n",
    "    rs = avg_gains / avg_losses.replace(0, float('inf'))\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    rsi_values = rsi.values\n",
    "    return pd.DataFrame({f\"rsi({length})\": rsi_values}, index=df.index)\n",
    "\n",
    "def calculate_macd(df: pd.DataFrame, fast_length: int, slow_length: int, signal_length: int) -> pd.DataFrame:\n",
    "    ema_fast = df['close'].ewm(span=fast_length, adjust=False).mean()\n",
    "    ema_slow = df['close'].ewm(span=slow_length, adjust=False).mean()\n",
    "    macd = ema_fast - ema_slow\n",
    "    signal = macd.ewm(span=signal_length, adjust=False).mean()\n",
    "    macd_values = macd.values\n",
    "    return pd.DataFrame({f\"macd({fast_length},{slow_length},{signal_length})\": macd_values}, index=df.index)  # No alignment needed for MACD\n",
    "\n",
    "def calculate_bollinger_bands(df: pd.DataFrame, length: int, std_dev: float) -> pd.DataFrame:\n",
    "    rolling_mean = df['close'].rolling(window=length).mean()\n",
    "    rolling_std = df['close'].rolling(window=length).std()\n",
    "    upper_band = rolling_mean + (rolling_std * std_dev)\n",
    "    lower_band = rolling_mean - (rolling_std * std_dev)\n",
    "    middle_values = rolling_mean.values\n",
    "    upper_values = upper_band.values\n",
    "    lower_values = lower_band.values\n",
    "    bb_df = pd.DataFrame({f'bb({length},{std_dev})_middle': middle_values, f'bb({length},{std_dev})_upper': upper_values, f'bb({length},{std_dev})_lower': lower_values}, index=df.index)\n",
    "    return bb_df\n",
    "\n",
    "def calculate_rvwap(df: pd.DataFrame, length: int) -> pd.DataFrame:\n",
    "    typical_price = (df['high'] + df['low'] + df['close']) / 3\n",
    "    rolling_volume = df['volume'].rolling(length).sum()\n",
    "    typical_price_x_volume = df[\"volume\"] * typical_price\n",
    "    rolling_typical_price_x_volume = typical_price_x_volume.rolling(length).sum()\n",
    "    vwap = rolling_typical_price_x_volume / rolling_volume\n",
    "    return pd.DataFrame({f\"rvwap({length})\": vwap.values}, index=df.index)\n",
    "\n",
    "# Example usage\n",
    "\n",
    "# SMA\n",
    "sma_length_param = Parameter(\"length\", \"integer\", min_val=1, max_val=200, default=20)\n",
    "factory.register(FunctionDefinition(\"SMA\", {\"length\": sma_length_param}, calculate_sma))\n",
    "\n",
    "# RSI\n",
    "rsi_length_param = Parameter(\"length\", \"integer\", min_val=1, max_val=200, default=14) # Different default length\n",
    "factory.register(FunctionDefinition(\"RSI\", {\"length\": rsi_length_param}, calculate_rsi))\n",
    "\n",
    "# MACD\n",
    "fast_length_param = Parameter(\"fast_length\", \"integer\", min_val=1, max_val=100, default=12)\n",
    "slow_length_param = Parameter(\"slow_length\", \"integer\", min_val=1, max_val=200, default=26)\n",
    "signal_length_param = Parameter(\"signal_length\", \"integer\", min_val=1, max_val=50, default=9)\n",
    "factory.register(FunctionDefinition(\"MACD\", {\"fast_length\": fast_length_param, \"slow_length\": slow_length_param, \"signal_length\": signal_length_param}, calculate_macd))\n",
    "\n",
    "# Bollinger Bands\n",
    "bb_length_param = Parameter(\"length\", \"integer\", min_val=1, max_val=200, default=20)\n",
    "std_dev_param = Parameter(\"std_dev\", \"real\", min_val=0.1, max_val=5.0, default=2.0, increment=0.1)\n",
    "factory.register(FunctionDefinition(\"Bollinger Bands\", {\"length\": bb_length_param, \"std_dev\": std_dev_param}, calculate_bollinger_bands))\n",
    "\n",
    "# VWAP\n",
    "vwap_length_param = Parameter(\"length\", \"integer\", min_val=1, max_val=200, default=20)\n",
    "factory.register(FunctionDefinition(\"RVWAP\", {\"length\": vwap_length_param}, calculate_rvwap))\n",
    "\n",
    "\n",
    "data = {\n",
    "    'date': ['2024-01-01', '2024-01-02', '2024-01-03', '2024-01-04', '2024-01-05', '2024-01-06', '2024-01-07', '2024-01-08', '2024-01-09', '2024-01-10',\n",
    "             '2024-01-11', '2024-01-12', '2024-01-13', '2024-01-14', '2024-01-15', '2024-01-16', '2024-01-17', '2024-01-18', '2024-01-19', '2024-01-20',\n",
    "             '2024-01-21', '2024-01-22', '2024-01-23', '2024-01-24', '2024-01-25', '2024-01-26', '2024-01-27', '2024-01-28', '2024-01-29', '2024-01-30'],\n",
    "    'symbol': ['ABC', 'ABC', 'ABC', 'ABC', 'ABC', 'ABC', 'ABC', 'ABC', 'ABC', 'ABC',\n",
    "               'ABC', 'ABC', 'ABC', 'ABC', 'ABC', 'ABC', 'ABC', 'ABC', 'ABC', 'ABC',\n",
    "               'ABC', 'ABC', 'ABC', 'ABC', 'ABC', 'ABC', 'ABC', 'ABC', 'ABC', 'ABC'],\n",
    "    'close': [150.25, 152.75, 151.50, 153.00, 154.25, 153.75, 155.00, 156.50, 155.25, 157.00,\n",
    "              158.25, 159.75, 158.50, 160.00, 161.25, 160.75, 162.00, 163.50, 162.25, 164.00,\n",
    "              165.25, 166.75, 165.50, 167.00, 168.25, 167.75, 169.00, 170.50, 169.25, 171.00],\n",
    "    'volume': [100000, 120000, 80000, 90000, 110000, 100000, 150000, 160000, 130000, 110000,\n",
    "               120000, 140000, 90000, 100000, 130000, 110000, 160000, 170000, 140000, 120000,\n",
    "               130000, 150000, 100000, 110000, 140000, 120000, 170000, 180000, 150000, 130000],\n",
    "    'high': [152.50, 155.00, 153.75, 155.25, 156.50, 156.00, 157.25, 158.75, 157.50, 159.25,\n",
    "             160.50, 162.00, 160.75, 162.25, 163.50, 163.00, 164.25, 165.75, 165.50, 167.25,\n",
    "             168.50, 170.00, 168.75, 170.25, 171.50, 171.00, 172.25, 173.75, 173.50, 175.25],\n",
    "    'low': [148.00, 150.50, 149.25, 150.75, 152.00, 151.50, 152.75, 154.25, 153.00, 154.75,\n",
    "            156.00, 157.50, 156.25, 157.75, 159.00, 158.50, 159.75, 161.25, 160.00, 161.75,\n",
    "            163.00, 164.50, 163.25, 164.75, 166.00, 165.50, 166.75, 168.25, 167.00, 168.75]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)  # No index\n",
    "\n",
    "# Calculate indicators\n",
    "\n",
    "sma_indicator = factory.parse(\"SMA(5)\")  # Or SMA(length=5)\n",
    "print(sma_indicator)\n",
    "sma_result = sma_indicator.calculate(df)\n",
    "df = df.join(sma_result)  # Add the result to your DataFrame\n",
    "\n",
    "rsi_indicator = factory.parse(\"RSI(14)\")  # Or RSI(length=14)\n",
    "rsi_result = rsi_indicator.calculate(df)\n",
    "df = df.join(rsi_result)\n",
    "\n",
    "macd_indicator = factory.parse(\"MACD(12, 26, 9)\")  # Or MACD(fast_length=12, slow_length=26, signal_length=9)\n",
    "macd_result = macd_indicator.calculate(df)\n",
    "df = df.join(macd_result)\n",
    "\n",
    "rvwap_indicator = factory.parse(\"RVWAP(20)\") # Or RVWAP(length=20)\n",
    "rvwap_result = rvwap_indicator.calculate(df)\n",
    "df = df.join(rvwap_result)\n",
    "\n",
    "print(sma_indicator)\n",
    "print(rsi_indicator)\n",
    "print(macd_indicator)\n",
    "print(rvwap_indicator)\n",
    "\n",
    "print(df)\n",
    "\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57dab89",
   "metadata": {
    "papermill": {
     "duration": 0.005738,
     "end_time": "2025-02-15T07:22:25.860357",
     "exception": false,
     "start_time": "2025-02-15T07:22:25.854619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c708b3",
   "metadata": {
    "papermill": {
     "duration": 0.005619,
     "end_time": "2025-02-15T07:22:25.871920",
     "exception": false,
     "start_time": "2025-02-15T07:22:25.866301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de64a0bc",
   "metadata": {
    "papermill": {
     "duration": 0.005672,
     "end_time": "2025-02-15T07:22:25.883453",
     "exception": false,
     "start_time": "2025-02-15T07:22:25.877781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4f54642",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T07:22:25.896710Z",
     "iopub.status.busy": "2025-02-15T07:22:25.896376Z",
     "iopub.status.idle": "2025-02-15T07:22:25.919631Z",
     "shell.execute_reply": "2025-02-15T07:22:25.918575Z"
    },
    "papermill": {
     "duration": 0.032331,
     "end_time": "2025-02-15T07:22:25.921504",
     "exception": false,
     "start_time": "2025-02-15T07:22:25.889173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed Grammar:\n",
      "<__main__.Grammar object at 0x7b684bdca950>\n",
      "\n",
      "Parse Tree:\n",
      "AAPL + MSFT * GOOG / 2.5\n",
      "ParseTreeNode(expression, value=None, children=[ParseTreeNode(term, value=None, children=[ParseTreeNode(factor, value=None, children=[ParseTreeNode(identifier, value=AAPL, children=[], start_index=0, end_index=0)], start_index=0, end_index=0)], start_index=0, end_index=0), ParseTreeNode(operator, value=+, children=[], start_index=1, end_index=1), ParseTreeNode(term, value=None, children=[ParseTreeNode(factor, value=None, children=[ParseTreeNode(identifier, value=MSFT, children=[], start_index=2, end_index=2)], start_index=2, end_index=2)], start_index=2, end_index=2)], start_index=0, end_index=2)\n",
      "\n",
      "Parse Tree 2:\n",
      " 'hello world' + \"another string\" - 123.45 * (variable_name / 2) \n",
      "ParseTreeNode(expression, value=None, children=[ParseTreeNode(term, value=None, children=[ParseTreeNode(factor, value=None, children=[ParseTreeNode(string, value=hello world, children=[], start_index=0, end_index=0)], start_index=0, end_index=0)], start_index=0, end_index=0), ParseTreeNode(operator, value=+, children=[], start_index=1, end_index=1), ParseTreeNode(term, value=None, children=[ParseTreeNode(factor, value=None, children=[ParseTreeNode(string, value=another string, children=[], start_index=2, end_index=2)], start_index=2, end_index=2)], start_index=2, end_index=2)], start_index=0, end_index=2)\n",
      "\n",
      "Parse Tree 3:\n",
      "TopN(top_n=2, field='return')\n",
      "ParseTreeNode(expression, value=None, children=[ParseTreeNode(term, value=None, children=[ParseTreeNode(factor, value=None, children=[ParseTreeNode(identifier, value=TopN, children=[], start_index=0, end_index=0), ParseTreeNode(operator, value=(, children=[], start_index=1, end_index=1), ParseTreeNode(arguments, value=None, children=[ParseTreeNode(argument, value=None, children=[ParseTreeNode(identifier, value=top_n, children=[], start_index=2, end_index=2), ParseTreeNode(operator, value==, children=[], start_index=3, end_index=3), ParseTreeNode(expression, value=None, children=[ParseTreeNode(term, value=None, children=[ParseTreeNode(factor, value=None, children=[ParseTreeNode(number, value=2, children=[], start_index=4, end_index=4)], start_index=4, end_index=4)], start_index=4, end_index=4)], start_index=4, end_index=4)], start_index=2, end_index=4), ParseTreeNode(operator, value=,, children=[], start_index=5, end_index=5), ParseTreeNode(arguments, value=None, children=[ParseTreeNode(argument, value=None, children=[ParseTreeNode(identifier, value=field, children=[], start_index=6, end_index=6), ParseTreeNode(operator, value==, children=[], start_index=7, end_index=7), ParseTreeNode(expression, value=None, children=[ParseTreeNode(term, value=None, children=[ParseTreeNode(factor, value=None, children=[ParseTreeNode(string, value=return, children=[], start_index=8, end_index=8)], start_index=8, end_index=8)], start_index=8, end_index=8)], start_index=8, end_index=8)], start_index=6, end_index=8)], start_index=6, end_index=8)], start_index=2, end_index=8), ParseTreeNode(operator, value=), children=[], start_index=9, end_index=9)], start_index=0, end_index=9)], start_index=0, end_index=9)], start_index=0, end_index=9)\n",
      "\n",
      "Parse Tree 4:\n",
      "TopN(top_n=2, field=return)\n",
      "ParseTreeNode(expression, value=None, children=[ParseTreeNode(term, value=None, children=[ParseTreeNode(factor, value=None, children=[ParseTreeNode(identifier, value=TopN, children=[], start_index=0, end_index=0), ParseTreeNode(operator, value=(, children=[], start_index=1, end_index=1), ParseTreeNode(arguments, value=None, children=[ParseTreeNode(argument, value=None, children=[ParseTreeNode(identifier, value=top_n, children=[], start_index=2, end_index=2), ParseTreeNode(operator, value==, children=[], start_index=3, end_index=3), ParseTreeNode(expression, value=None, children=[ParseTreeNode(term, value=None, children=[ParseTreeNode(factor, value=None, children=[ParseTreeNode(number, value=2, children=[], start_index=4, end_index=4)], start_index=4, end_index=4)], start_index=4, end_index=4)], start_index=4, end_index=4)], start_index=2, end_index=4), ParseTreeNode(operator, value=,, children=[], start_index=5, end_index=5), ParseTreeNode(arguments, value=None, children=[ParseTreeNode(argument, value=None, children=[ParseTreeNode(identifier, value=field, children=[], start_index=6, end_index=6), ParseTreeNode(operator, value==, children=[], start_index=7, end_index=7), ParseTreeNode(expression, value=None, children=[ParseTreeNode(term, value=None, children=[ParseTreeNode(factor, value=None, children=[ParseTreeNode(identifier, value=return, children=[], start_index=8, end_index=8)], start_index=8, end_index=8)], start_index=8, end_index=8)], start_index=8, end_index=8)], start_index=6, end_index=8)], start_index=6, end_index=8)], start_index=2, end_index=8), ParseTreeNode(operator, value=), children=[], start_index=9, end_index=9)], start_index=0, end_index=9)], start_index=0, end_index=9)], start_index=0, end_index=9)\n",
      "\n",
      "Parse Tree 5:\n",
      "AAPL+MSFT*GOOG/2.5>100&&(RSI(14)<30||close=='test')\n",
      "ParseTreeNode(expression, value=None, children=[ParseTreeNode(term, value=None, children=[ParseTreeNode(factor, value=None, children=[ParseTreeNode(identifier, value=AAPL, children=[], start_index=0, end_index=0)], start_index=0, end_index=0)], start_index=0, end_index=0), ParseTreeNode(operator, value=+, children=[], start_index=1, end_index=1), ParseTreeNode(term, value=None, children=[ParseTreeNode(factor, value=None, children=[ParseTreeNode(identifier, value=MSFT, children=[], start_index=2, end_index=2)], start_index=2, end_index=2)], start_index=2, end_index=2)], start_index=0, end_index=2)\n",
      "\n",
      "Parse Tree a:\n",
      "(10 - 1) - 1\n",
      "ParseTreeNode(expression, value=None, children=[ParseTreeNode(term, value=None, children=[ParseTreeNode(factor, value=None, children=[ParseTreeNode(operator, value=(, children=[], start_index=0, end_index=0), ParseTreeNode(expression, value=None, children=[ParseTreeNode(term, value=None, children=[ParseTreeNode(factor, value=None, children=[ParseTreeNode(number, value=10, children=[], start_index=1, end_index=1)], start_index=1, end_index=1)], start_index=1, end_index=1), ParseTreeNode(operator, value=-, children=[], start_index=2, end_index=2), ParseTreeNode(term, value=None, children=[ParseTreeNode(factor, value=None, children=[ParseTreeNode(number, value=1, children=[], start_index=3, end_index=3)], start_index=3, end_index=3)], start_index=3, end_index=3)], start_index=1, end_index=3), ParseTreeNode(operator, value=), children=[], start_index=4, end_index=4)], start_index=0, end_index=4)], start_index=0, end_index=4), ParseTreeNode(operator, value=-, children=[], start_index=5, end_index=5), ParseTreeNode(term, value=None, children=[ParseTreeNode(factor, value=None, children=[ParseTreeNode(number, value=1, children=[], start_index=6, end_index=6)], start_index=6, end_index=6)], start_index=6, end_index=6)], start_index=0, end_index=6)\n",
      "8\n",
      "\n",
      "Parse Tree b:\n",
      "SMA(length=10)\n",
      "ParseTreeNode(expression, value=None, children=[ParseTreeNode(term, value=None, children=[ParseTreeNode(factor, value=None, children=[ParseTreeNode(identifier, value=SMA, children=[], start_index=0, end_index=0), ParseTreeNode(operator, value=(, children=[], start_index=1, end_index=1), ParseTreeNode(arguments, value=None, children=[ParseTreeNode(argument, value=None, children=[ParseTreeNode(identifier, value=length, children=[], start_index=2, end_index=2), ParseTreeNode(operator, value==, children=[], start_index=3, end_index=3), ParseTreeNode(expression, value=None, children=[ParseTreeNode(term, value=None, children=[ParseTreeNode(factor, value=None, children=[ParseTreeNode(number, value=10, children=[], start_index=4, end_index=4)], start_index=4, end_index=4)], start_index=4, end_index=4)], start_index=4, end_index=4)], start_index=2, end_index=4)], start_index=2, end_index=4), ParseTreeNode(operator, value=), children=[], start_index=5, end_index=5)], start_index=0, end_index=5)], start_index=0, end_index=5)], start_index=0, end_index=5)\n",
      "SMA(length=10)\n",
      "\n",
      "Parse Tree c:\n",
      "10\n",
      "ParseTreeNode(expression, value=None, children=[ParseTreeNode(term, value=None, children=[ParseTreeNode(factor, value=None, children=[ParseTreeNode(number, value=10, children=[], start_index=0, end_index=0)], start_index=0, end_index=0)], start_index=0, end_index=0)], start_index=0, end_index=0)\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# FIXME: the grammar and reification modules do not correctly handle order of operations correctly for operations\n",
    "# that do not have the associative property. An easy workaround is to require parentheses.\n",
    "# The parser does not handle epsilon correctly either\n",
    "grammar_string = \"\"\"\n",
    "expression -> term \"+\" term\n",
    "expression -> term \"-\" term\n",
    "expression -> term \"*\" term\n",
    "expression -> term \"/\" term\n",
    "expression -> term\n",
    "term -> factor\n",
    "factor -> \"(\" expression \")\"\n",
    "factor -> number\n",
    "factor -> string\n",
    "factor -> identifier \"(\" arguments \")\"\n",
    "factor -> identifier\n",
    "arguments -> argument \",\" arguments\n",
    "arguments -> argument\n",
    "argument -> identifier \"=\" expression\n",
    "argument -> expression\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "## Example Usage:\n",
    "#grammar_string = \"\"\"\n",
    "#expression -> term more_terms\n",
    "#expression -> term\n",
    "#more_terms -> operator term more_terms\n",
    "#more_terms -> operator term\n",
    "#term -> factor more_factors\n",
    "#term -> factor\n",
    "#more_factors -> operator factor more_factors\n",
    "#more_factors -> operator factor\n",
    "#factor -> number\n",
    "#factor -> identifier\n",
    "#factor -> string\n",
    "#factor -> ( expression )\n",
    "#factor -> identifier ( arguments )\n",
    "#arguments -> expression more_arguments\n",
    "#arguments -> expression\n",
    "#more_arguments -> , expression more_arguments\n",
    "#more_arguments -> , arguments\n",
    "#\"\"\"\n",
    "\n",
    "grammar = Grammar(grammar_string)\n",
    "print(\"Parsed Grammar:\")\n",
    "print(grammar)\n",
    "\n",
    "expression = \"AAPL + MSFT * GOOG / 2.5\"\n",
    "parse_tree = grammar.parse(expression)\n",
    "print(\"\\nParse Tree:\")\n",
    "print(expression)\n",
    "print(parse_tree)\n",
    "\n",
    "expression2 = \" 'hello world' + \\\"another string\\\" - 123.45 * (variable_name / 2) \"\n",
    "parse_tree2 = grammar.parse(expression2)\n",
    "print(\"\\nParse Tree 2:\")\n",
    "print(expression2)\n",
    "print(parse_tree2)\n",
    "\n",
    "expression3 = \"TopN(top_n=2, field='return')\" # Test for nested functions\n",
    "parse_tree3 = grammar.parse(expression3)\n",
    "print(\"\\nParse Tree 3:\")\n",
    "print(expression3)\n",
    "print(parse_tree3)\n",
    "\n",
    "expression4 = \"TopN(top_n=2, field=return)\" # Test for nested functions without quotes\n",
    "parse_tree4 = grammar.parse(expression4)\n",
    "print(\"\\nParse Tree 4:\")\n",
    "print(expression4)\n",
    "print(parse_tree4)\n",
    "\n",
    "expression5 = \"AAPL+MSFT*GOOG/2.5>100&&(RSI(14)<30||close=='test')\"  # No spaces around operators\n",
    "parse_tree5 = grammar.parse(expression5)\n",
    "print(\"\\nParse Tree 5:\")\n",
    "print(expression5)\n",
    "print(parse_tree5)\n",
    "\n",
    "\n",
    "\n",
    "# ... (Placeholder functions for parsing remain the same)\n",
    "\n",
    "print(\"\\nParse Tree a:\")\n",
    "expression = \"(10 - 1) - 1\"\n",
    "print(expression)\n",
    "parse_tree = grammar.parse(expression)\n",
    "print(parse_tree)\n",
    "reified_expression = parse_tree.reify(factory)  # Call reify as a method\n",
    "print(reified_expression)\n",
    "\n",
    "# ... (Other examples  call reify as a method on the parse tree)\n",
    "print(\"\\nParse Tree b:\")\n",
    "expression = \"SMA(length=10)\"\n",
    "print(expression)\n",
    "parse_tree = grammar.parse(expression)\n",
    "print(parse_tree)\n",
    "reified_expression = parse_tree.reify(factory)\n",
    "print(reified_expression)\n",
    "\n",
    "expression = \"10\"\n",
    "print(\"\\nParse Tree c:\")\n",
    "print(expression)\n",
    "parse_tree = grammar.parse(expression)\n",
    "print(parse_tree)\n",
    "reified_expression = parse_tree.reify(factory)\n",
    "print(reified_expression)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00db3064",
   "metadata": {
    "papermill": {
     "duration": 0.005987,
     "end_time": "2025-02-15T07:22:25.933918",
     "exception": false,
     "start_time": "2025-02-15T07:22:25.927931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "109d8777",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T07:22:25.947474Z",
     "iopub.status.busy": "2025-02-15T07:22:25.947090Z",
     "iopub.status.idle": "2025-02-15T07:22:25.968980Z",
     "shell.execute_reply": "2025-02-15T07:22:25.967872Z"
    },
    "papermill": {
     "duration": 0.030799,
     "end_time": "2025-02-15T07:22:25.970859",
     "exception": false,
     "start_time": "2025-02-15T07:22:25.940060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# CLASS FunctionDefinition: __init__(self: None, name: builtins.str, parameters: builtins.dict, calculation_function: None, factory: None) -> None; __repr__(self: None) -> None; calculate(self: None, data: pandas.core.frame.DataFrame, params: builtins.dict) -> pandas.core.frame.DataFrame; create_function(self: None, kwargs: typing.Any) -> __main__.FunctionInstance; \n",
      "# CLASS FunctionFactory: __init__(self: None) -> None; __repr__(self: None) -> None; get(self: None, name: builtins.str) -> None; parse(self: None, indicator_string: builtins.str) -> __main__.FunctionInstance; register(self: None, function_definition: None) -> None; \n",
      "# CLASS FunctionInstance: __init__(self: None, name: builtins.str, parameters: builtins.dict, definition: None) -> None; __repr__(self: None) -> None; calculate(self: None, data: pandas.core.frame.DataFrame) -> None; \n",
      "# CLASS Grammar: __init__(self: None, grammar_string: builtins.str) -> None; build_parse_tree(self: None, tokens: builtins.list, start_symbol: builtins.str) -> typing.Union[__main__.ParseTreeNode, builtins.NoneType]; parse(self: None, input_string: builtins.str, start_symbol: builtins.str) -> None; tokenize(self: None, expression: builtins.str) -> builtins.list; \n",
      "# CLASS GrammarRule: __init__(self: None, left: builtins.str, right: builtins.list) -> None; __repr__(self: None) -> None; \n",
      "# CLASS Parameter: __init__(self: None, name: builtins.str, data_type: typing.Literal, min_val: typing.Union[builtins.int, builtins.float, builtins.NoneType], max_val: typing.Union[builtins.int, builtins.float, builtins.NoneType], default: typing.Union[typing.Any, builtins.NoneType], timeframe_defaults: typing.Union[builtins.dict, builtins.NoneType], increment: typing.Union[builtins.int, builtins.float, builtins.NoneType], allowed_strings: typing.Union[builtins.list, builtins.NoneType]) -> None; __repr__(self: None) -> None; get_default(self: None) -> typing.Any; get_possible_values(self: None) -> collections.abc.Iterable; \n",
      "# CLASS ParseTreeNode: __init__(self: None, type: builtins.str, value: typing.Union[builtins.str, builtins.NoneType], children: typing.Union[builtins.list, builtins.NoneType]) -> None; __repr__(self: None) -> None; reify(self: None, function_factory: None) -> None; \n",
      "# CLASS Token: __init__(self: None, type: builtins.str, value: builtins.str) -> None; __repr__(self: None) -> None; \n",
      "# FUNCTION _get_fully_qualified_type_name: _get_fully_qualified_type_name(type_hint: None) -> None; \n",
      "# FUNCTION calculate_bollinger_bands: calculate_bollinger_bands(df: pandas.core.frame.DataFrame, length: builtins.int, std_dev: builtins.float) -> pandas.core.frame.DataFrame; \n",
      "# FUNCTION calculate_macd: calculate_macd(df: pandas.core.frame.DataFrame, fast_length: builtins.int, slow_length: builtins.int, signal_length: builtins.int) -> pandas.core.frame.DataFrame; \n",
      "# FUNCTION calculate_rsi: calculate_rsi(df: pandas.core.frame.DataFrame, length: builtins.int) -> pandas.core.frame.DataFrame; \n",
      "# FUNCTION calculate_rvwap: calculate_rvwap(df: pandas.core.frame.DataFrame, length: builtins.int) -> pandas.core.frame.DataFrame; \n",
      "# FUNCTION calculate_sma: calculate_sma(df: pandas.core.frame.DataFrame, length: builtins.int) -> pandas.core.frame.DataFrame; \n",
      "# FUNCTION generate_simplified_signature_comment: generate_simplified_signature_comment(obj: None) -> None; \n",
      "# FUNCTION list_module_objects: list_module_objects(module: None) -> None; \n",
      "# FUNCTION percentile_screener_function: percentile_screener_function(df: None, field: None, percentile: None) -> None; \n",
      "# FUNCTION top_n_screener_function: top_n_screener_function(df: None, field: None, top_n: None) -> None; \n"
     ]
    }
   ],
   "source": [
    "# This code is used for prompt engineering\n",
    "\n",
    "def generate_simplified_signature_comment(obj):\n",
    "    \"\"\"Generates a simplified signature comment for a class or function,\n",
    "       clearly distinguishing between them.\n",
    "    \"\"\"\n",
    "\n",
    "    if inspect.isclass(obj):\n",
    "        comment = f\"# CLASS {obj.__name__}: \"  \n",
    "        members = inspect.getmembers(obj)\n",
    "    elif inspect.isfunction(obj):\n",
    "        comment = f\"# FUNCTION {obj.__name__}: \" \n",
    "        members = [(obj.__name__, obj)]  # Treat function as a single member\n",
    "    else:\n",
    "        return None  # Or raise an exception\n",
    "\n",
    "    for name, member in members:\n",
    "        if inspect.isfunction(member) or inspect.ismethod(member):\n",
    "            signature = inspect.signature(member)\n",
    "            params = []\n",
    "            for param in signature.parameters.values():\n",
    "                param_type = typing.get_type_hints(member).get(param.name)\n",
    "                param_type_str = _get_fully_qualified_type_name(param_type)\n",
    "                params.append(f\"{param.name}: {param_type_str}\")\n",
    "\n",
    "            return_type = typing.get_type_hints(member).get('return')\n",
    "            return_type_str = _get_fully_qualified_type_name(return_type)\n",
    "\n",
    "            comment += f\"{name}({', '.join(params)}) -> {return_type_str}; \"\n",
    "    return comment\n",
    "\n",
    "def _get_fully_qualified_type_name(type_hint):\n",
    "    if type_hint is None:\n",
    "        return \"None\"\n",
    "\n",
    "    origin = typing.get_origin(type_hint)  # Use typing.get_origin\n",
    "\n",
    "    if origin is not None:  # Generic type (List, Dict, etc.)\n",
    "        args = typing.get_args(type_hint)   # Use typing.get_args\n",
    "        if origin is typing.List:         # Use typing.List\n",
    "            arg_str = \", \".join(_get_fully_qualified_type_name(arg) for arg in args) if args else \"\"\n",
    "            return f\"typing.List[{arg_str}]\"\n",
    "        elif origin is typing.Dict:        # Use typing.Dict\n",
    "            arg_str = \", \".join(_get_fully_qualified_type_name(arg) for arg in args) if args else \"\"\n",
    "            return f\"typing.Dict[{arg_str}]\"\n",
    "        elif origin is typing.Optional:    # Use typing.Optional\n",
    "            arg_str = _get_fully_qualified_type_name(args[0]) if args else \"\"\n",
    "            return f\"typing.Optional[{arg_str}]\"\n",
    "        elif origin is typing.Tuple:       # Use typing.Tuple\n",
    "            arg_str = \", \".join(_get_fully_qualified_type_name(arg) for arg in args) if args else \"\"\n",
    "            return f\"typing.Tuple[{arg_str}]\"\n",
    "        elif origin is typing.Union:       # Use typing.Union. Added support for Union\n",
    "            arg_str = \", \".join(_get_fully_qualified_type_name(arg) for arg in args) if args else \"\"\n",
    "            return f\"typing.Union[{arg_str}]\"\n",
    "        else:\n",
    "            return origin.__module__ + \".\" + origin.__name__ if hasattr(origin, '__module__') else origin.__name__  # Handle other generics\n",
    "    elif hasattr(type_hint, '__module__') and hasattr(type_hint, '__name__'):  # Regular class\n",
    "        return type_hint.__module__ + \".\" + type_hint.__name__\n",
    "    elif hasattr(type_hint, '__name__'):  # Regular class\n",
    "        return type_hint.__name__\n",
    "    else:\n",
    "        return str(type_hint)  # Fallback to string representation\n",
    "\n",
    "def list_module_objects(module=None):\n",
    "    \"\"\"Lists all functions and classes defined in the current module.\n",
    "\n",
    "    Args:\n",
    "        module: The module to inspect. If None, defaults to the current module.\n",
    "\n",
    "    Returns:\n",
    "        A list of tuples, where each tuple contains the name and the object \n",
    "        (function or class).  Returns an empty list if no suitable objects are found.\n",
    "    \"\"\"\n",
    "\n",
    "    if module is None:\n",
    "        import sys\n",
    "        module = sys.modules[__name__]  # Get the current module\n",
    "\n",
    "    objects = []\n",
    "    for name, obj in inspect.getmembers(module):\n",
    "        if inspect.isfunction(obj) or inspect.isclass(obj):\n",
    "            if obj.__module__ == module.__name__: #check if object is defined in the current module\n",
    "                objects.append((name, obj))\n",
    "    return objects\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage:\n",
    "    module_objects = list_module_objects()\n",
    "\n",
    "    for name, obj in module_objects:\n",
    "        comment = generate_simplified_signature_comment(obj)\n",
    "        if comment:\n",
    "            print(comment)\n",
    "        #if you want to execute the prompt engineering on the current module\n",
    "        #and write the output to a file, you can do this:\n",
    "        # with open(\"prompt_engineering_output.txt\", \"a\") as f:\n",
    "        #     f.write(comment + \"\\n\")\n",
    "\n",
    "    # To list objects from another module (if needed):\n",
    "    # import my_other_module\n",
    "    # other_module_objects = list_module_objects(my_other_module)\n",
    "    # for name, obj in other_module_objects:\n",
    "    #   # ... process objects from the other module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aa1297",
   "metadata": {
    "papermill": {
     "duration": 0.006052,
     "end_time": "2025-02-15T07:22:25.983582",
     "exception": false,
     "start_time": "2025-02-15T07:22:25.977530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe7d61f",
   "metadata": {
    "papermill": {
     "duration": 0.00592,
     "end_time": "2025-02-15T07:22:25.995708",
     "exception": false,
     "start_time": "2025-02-15T07:22:25.989788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6605508,
     "sourceId": 10753109,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4.913869,
   "end_time": "2025-02-15T07:22:26.622940",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-15T07:22:21.709071",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
